{"cells":[{"cell_type":"code","execution_count":924,"metadata":{},"outputs":[],"source":["import plotly.graph_objects as go\n","import numpy as np\n","\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime, timezone\n","import os\n","import logging\n","from typing import List, Dict\n","from sqlalchemy import create_engine, text\n","from sqlalchemy.engine.base import Engine\n","from dotenv import load_dotenv\n","\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","\n","import json\n","import jinja2\n","\n","import numpy as np\n","from sklearn.metrics import mean_squared_error, r2_score\n","import pandas as pd\n","from datetime import datetime, timezone  # Changed this line\n","import json\n","from sqlalchemy import create_engine, text\n","from typing import Dict"]},{"cell_type":"markdown","metadata":{},"source":["# Inputs"]},{"cell_type":"code","execution_count":925,"metadata":{},"outputs":[],"source":["# Database configuration\n","db_config = {\n","    'dbname': 'allora',\n","    'user': 'postgres',\n","    'password': 'postgres',\n","    'host': 'localhost',\n","    'port': '5433'\n","}\n","\n","# inputs\n","topic_id = 1\n","lookback_epochs = 10000 # will grab data from this many epochs ago\n","lookback_blocks = 10000 # will grab data from this many blocks ago (only used for tokenomics)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Queries and db scripts"]},{"cell_type":"code","execution_count":926,"metadata":{},"outputs":[],"source":["class DatabaseManager:\n","    def __init__(self, read_config: Dict[str, str], write_config: Dict[str, str]):\n","        self.read_config = read_config\n","        self.write_config = write_config\n","        self.read_engine: Engine = None\n","        self.write_engine: Engine = None\n","\n","    def connect(self):\n","        try:\n","            read_connection_string = f\"postgresql://{self.read_config['user']}:{self.read_config['password']}@{self.read_config['host']}:{self.read_config['port']}/{self.read_config['dbname']}\"\n","            self.read_engine = create_engine(read_connection_string, future=True)\n","            print(\"Connected to the read database\")\n","\n","            write_connection_string = f\"postgresql://{self.write_config['user']}:{self.write_config['password']}@{self.write_config['host']}:{self.write_config['port']}/{self.write_config['dbname']}\"\n","            self.write_engine = create_engine(write_connection_string, future=True)\n","            print(\"Connected to the write database\")\n","        except Exception as e:\n","            print(f\"Error connecting to databases: {e}\")\n","            raise\n","\n","    def execute_query(self, query: str) -> pd.DataFrame:\n","        try:\n","            with self.read_engine.connect() as connection:\n","                result = connection.execute(text(query))\n","                return pd.DataFrame(result.fetchall(), columns=result.keys())\n","        except Exception as e:\n","            print(f\"Error executing query: {e}\")\n","            raise\n","\n","    def create_metrics_table(self):\n","        print(\"Creating or verifying the research metrics table in the write database...\")\n","        create_table_query = text(\"\"\"\n","        CREATE TABLE IF NOT EXISTS research_metrics (\n","            id SERIAL PRIMARY KEY,\n","            topic_id INTEGER NOT NULL,\n","            epoch INTEGER NOT NULL,\n","            address VARCHAR(255),\n","            metric_value DOUBLE PRECISION,\n","            metric_name VARCHAR(255) NOT NULL,\n","            updated_at TIMESTAMP WITH TIME ZONE NOT NULL\n","        );\n","        \"\"\")\n","        \n","        try:\n","            with self.write_engine.connect() as connection:\n","                connection.execute(create_table_query)\n","                connection.commit()\n","            print(\"Research metrics table created or verified in the write database.\")\n","        except Exception as e:\n","            print(f\"Error creating or verifying research metrics table: {e}\")\n","            raise\n","\n","    def insert_metrics(self, df: pd.DataFrame):\n","        try:\n","            # Ensure all expected columns are present\n","            expected_columns = ['topic_id', 'epoch', 'address', 'metric_value', 'metric_name', 'updated_at']\n","            for col in expected_columns:\n","                if col not in df.columns:\n","                    df[col] = None  # Add missing columns with None values\n","\n","            # Convert 'updated_at' to datetime if it's not already\n","            if df['updated_at'].dtype != 'datetime64[ns]':\n","                df['updated_at'] = pd.to_datetime(df['updated_at'])\n","\n","            # Convert 'address' column to string type\n","            df['address'] = df['address'].astype(str)\n","\n","            # Insert data into the database\n","            df.to_sql('research_metrics', self.write_engine, if_exists='append', index=False)\n","            print(f\"Inserted {len(df)} rows into research metrics table\")\n","        except Exception as e:\n","            print(f\"Error inserting metrics into database: {e}\")\n","            raise\n","\n","    def close(self):\n","        if self.read_engine:\n","            self.read_engine.dispose()\n","        if self.write_engine:\n","            self.write_engine.dispose()\n","        print(\"Database connections closed\")\n","\n","    def set_global_lock(self):\n","        try:\n","            lock_entry = pd.DataFrame({\n","                'topic_id': [0],  # Use 0 as a special topic_id for global lock\n","                'epoch': [-1],\n","                'metric_value': [0.0],\n","                'metric_name': ['global_lock'],\n","                'updated_at': [datetime.now(timezone.utc)]\n","            })\n","            self.insert_metrics(lock_entry)\n","            print(\"Global lock set\")\n","        except Exception as e:\n","            print(f\"Error setting global lock: {e}\")\n","            raise\n","\n","    def check_global_lock(self) -> bool:\n","        query = \"\"\"\n","        SELECT EXISTS (\n","            SELECT 1 FROM research_metrics \n","            WHERE topic_id = 0 AND epoch = -1 AND metric_name = 'global_lock'\n","        ) AS is_locked;\n","        \"\"\"\n","        try:\n","            with self.read_engine.connect() as connection:\n","                result = connection.execute(text(query))\n","                return result.scalar()\n","        except Exception as e:\n","            print(f\"Error checking global lock: {e}\")\n","            raise\n","\n","    def remove_global_lock(self):\n","        query = \"\"\"\n","        DELETE FROM research_metrics \n","        WHERE topic_id = 0 AND epoch = -1 AND metric_name = 'global_lock';\n","        \"\"\"\n","        try:\n","            with self.write_engine.connect() as connection:\n","                connection.execute(text(query))\n","                connection.commit()\n","            print(\"Global lock removed\")\n","        except Exception as e:\n","            print(f\"Error removing global lock: {e}\")\n","            raise\n","\n","class Metric:\n","    def __init__(self, name: str, topic_id: int, epoch_length: int):\n","        self.name = name\n","        self.topic_id = topic_id\n","        self.epoch_length = epoch_length\n","\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        raise NotImplementedError(\"Subclasses must implement this method\")\n","class ValidatorRewardMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        WITH block_rewards AS (\n","            SELECT \n","                height_tx,\n","                validator,\n","                amount::numeric / (10^18) as reward\n","            FROM \n","                validator_rewards\n","            WHERE \n","                height_tx >= {min_block_height}\n","        )\n","        SELECT \n","            height_tx,\n","            ARRAY_AGG(reward) as rewards\n","        FROM \n","            block_rewards\n","        GROUP BY \n","            height_tx\n","        ORDER BY \n","            height_tx ASC;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        \n","        def compute_validator_reward_metric(rewards):\n","            # Parameters\n","            C_v = 10\n","            beta = 0.25\n","            \n","            # Convert rewards to numpy array\n","            rewards = np.array(rewards)\n","            \n","            # Normalize rewards (P_iv)\n","            total_rewards = np.sum(rewards)\n","            if total_rewards == 0:\n","                return 0\n","                \n","            P_iv = rewards / total_rewards\n","            \n","            # Compute effective number of validators\n","            n_v = len(rewards)\n","            n_v_eff = 1 / np.sum(P_iv**2)\n","            \n","            # Compute scaled entropy\n","            # Add small epsilon to avoid log(0)\n","            epsilon = 1e-10\n","            P_iv = np.clip(P_iv, epsilon, 1)\n","            E_v = -np.sum(P_iv * np.log(P_iv) * (n_v_eff/n_v)**beta)\n","            \n","            # Normalize and scale entropy\n","            H_v = 10**(C_v * (E_v/np.log(n_v) - 1))\n","            \n","            return H_v\n","\n","        # Calculate metric for each block\n","        results = []\n","        for _, row in df.iterrows():\n","            metric_value = compute_validator_reward_metric(row['rewards'])\n","            results.append({\n","                'epoch': row['height_tx'],\n","                'metric_value': metric_value,\n","                'topic_id': 0,\n","                'metric_name': self.name,\n","                'updated_at': datetime.now(timezone.utc),\n","                'address': None\n","            })\n","        \n","        if not results:\n","            return pd.DataFrame()\n","            \n","        result_df = pd.DataFrame(results)\n","        return result_df\n","class ForecastHealthMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        SELECT\n","            {self.topic_id} AS topic_id,\n","            FLOOR(height_tx / {self.epoch_length}) AS epoch,\n","            SUM(CAST(score AS FLOAT)) AS metric_value\n","        FROM \n","            topic_forecasting_scores\n","        WHERE \n","            topic_id = {self.topic_id} AND\n","            height_tx >= {min_block_height}\n","        GROUP BY\n","            epoch\n","        ORDER BY \n","            epoch DESC;\n","        \"\"\"\n","        df = db_manager.execute_query(query)\n","        df['metric_name'] = self.name\n","        df['updated_at'] = datetime.now(timezone.utc)\n","        df['address'] = None\n","        return df\n","\n","class ReputerScoreMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        lookback_blocks = min_block_height\n","        query = f\"\"\"\n","        WITH active_inferers_per_epoch AS (\n","            SELECT \n","                FLOOR(height / {self.epoch_length}) AS epoch,  \n","                address\n","            FROM \n","                ema_scores\n","            WHERE \n","                is_active = true  \n","                AND height >= {min_block_height}  \n","                AND type = 'ACTOR_TYPE_REPUTER'\n","            GROUP BY \n","                epoch, address\n","        )\n","        SELECT \n","            a.epoch, \n","            s.address, \n","            SUM(s.value) AS average_score\n","        FROM \n","            scores s\n","        JOIN \n","            active_inferers_per_epoch a\n","            ON FLOOR(s.height / {self.epoch_length}) = a.epoch\n","            AND s.address = a.address\n","        WHERE \n","            s.topic_id = {self.topic_id}\n","        AND\n","            s.type = 'ACTOR_TYPE_REPUTER'\n","        AND\n","            s.height >= {min_block_height}\n","        GROUP BY \n","            a.epoch, \n","            s.address\n","        ORDER BY \n","            a.epoch DESC, \n","            s.address;\n","        \"\"\"\n","        \n","        raw_reputer_scores = db_manager.execute_query(query)\n","        \n","        reputer_counts = raw_reputer_scores.groupby('epoch')['address'].nunique().reset_index()\n","        epsilon = 10**-6\n","\n","        reputer_counts.columns = ['epoch', 'num_reputers']\n","        reputer_stats = raw_reputer_scores.groupby('epoch')['average_score'].agg(['mean', 'std']).reset_index()\n","        reputer_stats.columns = ['epoch', 'reputer_mean_score', 'reputer_std_score']\n","        reputer_summary = reputer_counts.merge(reputer_stats, on='epoch', how='outer')\n","\n","        def calculate_reputer_score_metric(row):\n","            if row['reputer_mean_score'] <= 0:\n","                return 0\n","            if pd.isna(row['reputer_std_score']):  # Case of a single reputer\n","                return np.log10(row['reputer_mean_score'])\n","            result = np.log10(row['reputer_mean_score'] / (row['reputer_std_score']**2 + epsilon))\n","            return 0 if np.isinf(result) else result\n","\n","        reputer_summary['metric_value'] = reputer_summary.apply(calculate_reputer_score_metric, axis=1)\n","\n","        # Create a new DataFrame with all required columns\n","        result_df = pd.DataFrame({\n","            'epoch': reputer_summary['epoch'],\n","            'metric_value': reputer_summary['metric_value'],\n","            'topic_id': self.topic_id,\n","            'metric_name': self.name,\n","            'updated_at': datetime.now(timezone.utc)\n","        })\n","        \n","        result_df['address'] = None\n","        return result_df\n","\n","class SortitionScoreMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        WITH ranked_scores AS (\n","            SELECT\n","                address,\n","                FLOOR(height / {self.epoch_length}) AS epoch,\n","                is_active,\n","                score,\n","                LAG(is_active) OVER (PARTITION BY address ORDER BY height) AS prev_is_active,\n","                LAG(score) OVER (PARTITION BY address ORDER BY height) AS prev_score\n","            FROM\n","                ema_scores\n","            WHERE\n","                topic_id = {self.topic_id}\n","                AND type = 'ACTOR_TYPE_INFERER_UNSPECIFIED'\n","                AND height >= {min_block_height}\n","        )\n","        SELECT\n","            epoch,\n","            COALESCE((AVG(CASE WHEN prev_is_active = false AND is_active = true THEN score END) -\n","                      AVG(CASE WHEN prev_is_active = true AND is_active = false THEN prev_score END)) / \n","                      NULLIF(COUNT(CASE WHEN prev_is_active = true AND is_active = false THEN address END), 0), 0) \n","            AS metric_value\n","        FROM\n","            ranked_scores\n","        GROUP BY\n","            epoch\n","        ORDER BY\n","            epoch DESC;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        df['topic_id'] = self.topic_id\n","        df['metric_name'] = self.name\n","        df['updated_at'] = datetime.now(timezone.utc)\n","        df['address'] = None\n","        return df\n","\n","class SortitionTimeMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        WITH ranked_scores AS (\n","            SELECT\n","                address,\n","                FLOOR(height / {self.epoch_length}) AS epoch,\n","                is_active,\n","                LAG(is_active) OVER (PARTITION BY address ORDER BY height) AS prev_is_active\n","            FROM\n","                ema_scores\n","            WHERE\n","                topic_id = {self.topic_id}\n","                AND type = 'ACTOR_TYPE_INFERER_UNSPECIFIED'\n","                AND height >= {min_block_height}\n","        ),\n","        epoch_metrics AS (\n","            SELECT\n","                epoch,\n","                COUNT(DISTINCT address) as total_addresses,\n","                COUNT(CASE WHEN prev_is_active = false AND is_active = true THEN address END) as new_active\n","            FROM ranked_scores\n","            WHERE prev_is_active IS NOT NULL\n","            GROUP BY epoch\n","        )\n","        SELECT\n","            epoch,\n","            total_addresses::float / (new_active + 1e-6) AS metric_value\n","        FROM epoch_metrics\n","        ORDER BY epoch DESC;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        df['topic_id'] = self.topic_id\n","        df['metric_name'] = self.name\n","        df['updated_at'] = datetime.now(timezone.utc)\n","        df['address'] = None\n","        return df\n","\n","class LifetimeMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        WITH ranked_scores AS (\n","            SELECT\n","                address,\n","                FLOOR(height / {self.epoch_length}) AS epoch,\n","                is_active,\n","                LAG(is_active) OVER (PARTITION BY address ORDER BY height) AS prev_is_active\n","            FROM\n","                ema_scores\n","            WHERE\n","                topic_id = {self.topic_id}\n","                AND type = 'ACTOR_TYPE_INFERER_UNSPECIFIED'\n","                AND height >= {min_block_height}\n","        ),\n","        epoch_metrics AS (\n","            SELECT\n","                epoch,\n","                COUNT(CASE WHEN prev_is_active = false AND is_active = true THEN address END) as new_active,\n","                COUNT(CASE WHEN is_active = true THEN address END) as active_inferrers\n","            FROM ranked_scores\n","            WHERE prev_is_active IS NOT NULL\n","            GROUP BY epoch\n","        ),\n","        filled_metrics AS (\n","            SELECT\n","                epoch,\n","                new_active,\n","                COALESCE(\n","                    active_inferrers,\n","                    (SELECT active_inferrers \n","                     FROM epoch_metrics e2 \n","                     WHERE e2.epoch < epoch_metrics.epoch \n","                       AND e2.active_inferrers IS NOT NULL \n","                     ORDER BY e2.epoch DESC \n","                     LIMIT 1)\n","                ) as active_inferrers\n","            FROM epoch_metrics\n","        )\n","        SELECT\n","            epoch,\n","            active_inferrers::float / (new_active + 1e-6) AS metric_value\n","        FROM filled_metrics\n","        WHERE active_inferrers > 0\n","        ORDER BY epoch DESC;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        df['topic_id'] = self.topic_id\n","        df['metric_name'] = self.name\n","        df['updated_at'] = datetime.now(timezone.utc)\n","        df['address'] = None\n","        return df\n","\n","class InfererHealthMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        losses_query = f\"\"\"\n","        SELECT\n","            FLOOR(height / {self.epoch_length}) AS epoch,\n","            SUM(CAST(combined_value AS FLOAT)) AS total_combined_value_per_epoch\n","        FROM \n","            networklosses\n","        WHERE \n","            topic_id = {self.topic_id}\n","            AND height >= {min_block_height}\n","        GROUP BY\n","            epoch\n","        ORDER BY \n","            epoch DESC;\n","        \"\"\"\n","        \n","        inferences_query = f\"\"\"\n","        WITH active_inferers AS (\n","            SELECT DISTINCT\n","                address,\n","                FLOOR(height / {self.epoch_length}) AS epoch\n","            FROM \n","                ema_scores\n","            WHERE \n","                topic_id = {self.topic_id}\n","                AND is_active = true\n","                AND height >= {min_block_height}\n","        )\n","        SELECT\n","            FLOOR(i.block_height / {self.epoch_length}) AS epoch,\n","            i.value,\n","            i.inferer\n","        FROM \n","            inferences i\n","        JOIN \n","            active_inferers a ON i.inferer = a.address AND FLOOR(i.block_height / {self.epoch_length}) = a.epoch\n","        WHERE \n","            i.topic_id = {self.topic_id}\n","            AND i.block_height >= {min_block_height}\n","        ORDER BY\n","            epoch DESC;\n","        \"\"\"\n","\n","        losses_df = db_manager.execute_query(losses_query)\n","        inferences_df = db_manager.execute_query(inferences_query)\n","\n","        print(f\"Inferences DataFrame shape: {inferences_df.shape}\")\n","        print(f\"Inferences DataFrame columns: {inferences_df.columns}\")\n","        print(f\"Inferences DataFrame sample:\\n{inferences_df.head()}\")\n","\n","        # Calculate mean distance in Python\n","        inferences_df['value'] = inferences_df['value'].astype(float)\n","        mean_inference = inferences_df.groupby('epoch')['value'].transform('mean')\n","        inferences_df['distance'] = abs(inferences_df['value'] - mean_inference)\n","        mean_distance_df = inferences_df.groupby('epoch')['distance'].mean().reset_index()\n","        mean_distance_df.columns = ['epoch', 'mean_distance_to_mean_inference']\n","\n","        # Modify the raw inference calculation to include the address\n","        raw_inference_df = inferences_df.groupby(['epoch', 'inferer'])['value'].mean().reset_index()\n","        raw_inference_df.columns = ['epoch', 'address', 'raw_inference']\n","\n","        print(f\"Raw inference DataFrame shape: {raw_inference_df.shape}\")\n","        print(f\"Raw inference DataFrame columns: {raw_inference_df.columns}\")\n","        print(f\"Raw inference DataFrame sample:\\n{raw_inference_df.head()}\")\n","\n","        # Merge the dataframes on 'epoch'\n","        merged_df = pd.merge(mean_distance_df, losses_df, on='epoch', how='outer')\n","\n","        # Calculate the inferer health metric\n","        merged_df['inferer_health'] = np.log10(merged_df['mean_distance_to_mean_inference'] / (10**merged_df['total_combined_value_per_epoch']))\n","\n","        # Prepare the inferer health DataFrame\n","        inferer_health_df = pd.DataFrame({\n","            'epoch': merged_df['epoch'],\n","            'metric_value': merged_df['inferer_health'],\n","            'topic_id': self.topic_id,\n","            'metric_name': 'infererhealth',\n","            'updated_at': datetime.now(timezone.utc),\n","            'address': None\n","        })\n","        \n","        # Prepare the raw inference DataFrame\n","        raw_inference_df = pd.DataFrame({\n","            'epoch': raw_inference_df['epoch'],\n","            'address': raw_inference_df['address'],\n","            'metric_value': raw_inference_df['raw_inference'],\n","            'topic_id': self.topic_id,\n","            'metric_name': 'raw_inference',\n","            'updated_at': datetime.now(timezone.utc)\n","        })\n","\n","        print(f\"Inferer health DataFrame shape: {inferer_health_df.shape}\")\n","        print(f\"Inferer health DataFrame columns: {inferer_health_df.columns}\")\n","        print(f\"Inferer health DataFrame sample:\\n{inferer_health_df.head()}\")\n","\n","        # Concatenate both DataFrames\n","        result_df = pd.concat([inferer_health_df, raw_inference_df], ignore_index=True)\n","\n","        print(f\"Result DataFrame shape: {result_df.shape}\")\n","        print(f\"Result DataFrame columns: {result_df.columns}\")\n","        print(f\"Result DataFrame sample:\\n{result_df.head()}\")\n","\n","        # Remove rows with null metric values\n","        result_df = result_df.dropna(subset=['metric_value'])\n","\n","        print(f\"Final result DataFrame shape: {result_df.shape}\")\n","        print(f\"Final result DataFrame columns: {result_df.columns}\")\n","        print(f\"Final result DataFrame sample:\\n{result_df.head()}\")\n","\n","        return result_df\n","\n","class InfererLossesMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        SELECT \n","            FLOOR(nl.height / {self.epoch_length}) AS epoch,\n","            bv.worker AS address,\n","            CAST(bv.value AS FLOAT) AS metric_value\n","        FROM \n","            networkloss_bundle_values bv\n","        JOIN \n","            networklosses nl \n","            ON bv.bundle_id = nl.id              \n","        WHERE \n","            nl.topic_id = {self.topic_id}          \n","            AND nl.height >= {min_block_height}  \n","            AND bv.reputer_value_type = 'InfererValues'  \n","        ORDER BY \n","            nl.height DESC;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        df['topic_id'] = self.topic_id\n","        df['metric_name'] = self.name\n","        df['updated_at'] = datetime.now(timezone.utc)\n","        return df\n","\n","class ForecasterLossesMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        SELECT \n","            FLOOR(nl.height / {self.epoch_length}) AS epoch,\n","            bv.worker AS address,\n","            CAST(bv.value AS FLOAT) AS metric_value\n","        FROM \n","            networkloss_bundle_values bv\n","        JOIN \n","            networklosses nl \n","            ON bv.bundle_id = nl.id              \n","        WHERE \n","            nl.topic_id = {self.topic_id}          \n","            AND nl.height >= {min_block_height}  \n","            AND bv.reputer_value_type = 'ForecasterValues'  \n","        ORDER BY \n","            nl.height DESC;\n","        \"\"\"\n","        df = db_manager.execute_query(query)\n","        df['topic_id'] = self.topic_id\n","        df['metric_name'] = self.name\n","        df['updated_at'] = datetime.now(timezone.utc)\n","        return df\n","\n","class NetworkLossesMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        SELECT\n","            FLOOR(height / {self.epoch_length}) AS epoch,\n","            SUM(CAST(combined_value AS FLOAT)) AS combined_losses,\n","            SUM(CAST(naive_value AS FLOAT)) AS naive_losses\n","        FROM \n","            networklosses\n","        WHERE \n","            topic_id = {self.topic_id}\n","            AND height >= {min_block_height}\n","        GROUP BY\n","            epoch\n","        ORDER BY \n","            epoch DESC;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        \n","        # Create separate rows for combined and naive losses\n","        combined_df = df[['epoch', 'combined_losses']].rename(columns={'combined_losses': 'metric_value'})\n","        combined_df['metric_name'] = 'combined_losses'\n","        \n","        naive_df = df[['epoch', 'naive_losses']].rename(columns={'naive_losses': 'metric_value'})\n","        naive_df['metric_name'] = 'naive_losses'\n","        \n","        result_df = pd.concat([combined_df, naive_df], ignore_index=True)\n","        result_df['topic_id'] = self.topic_id\n","        result_df['updated_at'] = datetime.now(timezone.utc)\n","        result_df['address'] = None\n","        \n","        return result_df\n","\n","class RawReputerScoreMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        SELECT\n","            FLOOR(height / {self.epoch_length}) AS epoch,\n","            address,\n","            CAST(value AS FLOAT) AS metric_value\n","        FROM \n","            scores\n","        WHERE \n","            topic_id = {self.topic_id}\n","            AND height >= {min_block_height}\n","            AND type = 'ACTOR_TYPE_REPUTER'\n","        ORDER BY \n","            epoch DESC, address;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        df['topic_id'] = self.topic_id\n","        df['metric_name'] = self.name\n","        df['updated_at'] = datetime.now(timezone.utc)\n","        return df\n","\n","class RawInfererScoreMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        SELECT\n","            FLOOR(height / {self.epoch_length}) AS epoch,\n","            address,\n","            CAST(value AS FLOAT) AS metric_value\n","        FROM \n","            scores\n","        WHERE \n","            topic_id = {self.topic_id}\n","            AND height >= {min_block_height}\n","            AND type = 'ACTOR_TYPE_INFERER_UNSPECIFIED'\n","        ORDER BY \n","            epoch DESC, address;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        df['topic_id'] = self.topic_id\n","        df['metric_name'] = self.name\n","        df['updated_at'] = datetime.now(timezone.utc)\n","        return df\n","\n","class RawForecasterScoreMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        SELECT\n","            FLOOR(height / {self.epoch_length}) AS epoch,\n","            address,\n","            CAST(value AS FLOAT) AS metric_value\n","        FROM \n","            scores\n","        WHERE \n","            topic_id = {self.topic_id}\n","            AND height >= {min_block_height}\n","            AND type = 'ACTOR_TYPE_FORECASTER'\n","        ORDER BY \n","            epoch DESC, address;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        df['topic_id'] = self.topic_id\n","        df['metric_name'] = self.name\n","        df['updated_at'] = datetime.now(timezone.utc)\n","        return df\n","\n","class RawInfererRewardMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        SELECT\n","            FLOOR(height / {self.epoch_length}) AS epoch,\n","            address,\n","            CAST(value AS FLOAT) AS metric_value\n","        FROM \n","            rewards\n","        WHERE \n","            topic_id = {self.topic_id}\n","            AND height >= {min_block_height}\n","            AND type = 'ACTOR_TYPE_INFERER_UNSPECIFIED'\n","        ORDER BY \n","            epoch DESC, address;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        df['topic_id'] = self.topic_id\n","        df['metric_name'] = self.name\n","        df['updated_at'] = datetime.now(timezone.utc)\n","        return df\n","\n","class RawForecasterRewardMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        SELECT\n","            FLOOR(height / {self.epoch_length}) AS epoch,\n","            address,\n","            CAST(value AS FLOAT) AS metric_value\n","        FROM \n","            rewards\n","        WHERE \n","            topic_id = {self.topic_id}\n","            AND height >= {min_block_height}\n","            AND type = 'ACTOR_TYPE_FORECASTER'\n","        ORDER BY \n","            epoch DESC, address;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        df['topic_id'] = self.topic_id\n","        df['metric_name'] = self.name\n","        df['updated_at'] = datetime.now(timezone.utc)\n","        return df\n","\n","class RawReputerRewardMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        SELECT\n","            FLOOR(height / {self.epoch_length}) AS epoch,\n","            address,\n","            CAST(value AS FLOAT) AS metric_value\n","        FROM \n","            rewards\n","        WHERE \n","            topic_id = {self.topic_id}\n","            AND height >= {min_block_height}\n","            AND type = 'ACTOR_TYPE_REPUTER'\n","        ORDER BY \n","            epoch DESC, address;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        df['topic_id'] = self.topic_id\n","        df['metric_name'] = self.name\n","        df['updated_at'] = datetime.now(timezone.utc)\n","        return df\n","\n","class RawForecastsMetric(Metric):\n","    def calculate(self, db_manager: DatabaseManager, min_block_height: int) -> pd.DataFrame:\n","        query = f\"\"\"\n","        SELECT\n","            FLOOR(f.block_height / {self.epoch_length}) AS epoch,\n","            f.block_height,\n","            f.id AS forecast_id,\n","            fv.value AS metric_value,\n","            fv.inferer AS address\n","        FROM \n","            forecasts f\n","        JOIN \n","            forecast_values fv ON f.id = fv.forecast_id\n","        WHERE \n","            f.topic_id = {self.topic_id}\n","            AND f.block_height >= {min_block_height}\n","        ORDER BY \n","            f.block_height DESC, f.id, fv.inferer;\n","        \"\"\"\n","        \n","        df = db_manager.execute_query(query)\n","        \n","        # Only keep the columns that match our table schema\n","        result_df = pd.DataFrame({\n","            'topic_id': self.topic_id,\n","            'epoch': df['epoch'],\n","            'address': df['address'],\n","            'metric_value': df['metric_value'],\n","            'metric_name': self.name,\n","            'updated_at': datetime.now(timezone.utc)\n","        })\n","        \n","        return result_df"]},{"cell_type":"code","execution_count":927,"metadata":{},"outputs":[],"source":["def update_specific_topic(db_manager: DatabaseManager, topic_id: int):\n","    if db_manager.check_global_lock():\n","        print(f\"Global lock is active. Skipping update for topic {topic_id}.\")\n","        return\n","\n","    try:\n","        db_manager.set_global_lock()\n","\n","        # Fetch the specific topic\n","        topic_query = f\"SELECT id AS topic_id, epoch_length FROM topics WHERE id = {topic_id};\"\n","        topic_df = db_manager.execute_query(topic_query)\n","        \n","        if topic_df.empty:\n","            print(f\"Topic {topic_id} not found.\")\n","            return\n","        \n","        row = topic_df.iloc[0]\n","        epoch_length = int(row['epoch_length'])\n","        \n","        print(f\"Processing topic {topic_id} with epoch length {epoch_length}\")\n","\n","        metric_classes = [\n","            ValidatorRewardMetric, InfererLossesMetric, ForecastHealthMetric, ReputerScoreMetric,\n","            SortitionScoreMetric, SortitionTimeMetric, LifetimeMetric,\n","            InfererHealthMetric, ForecasterLossesMetric, NetworkLossesMetric,\n","            RawForecastsMetric, RawReputerScoreMetric, RawInfererScoreMetric,\n","            RawForecasterScoreMetric, RawInfererRewardMetric, RawForecasterRewardMetric,\n","            RawReputerRewardMetric\n","        ]\n","\n","        for i, MetricClass in enumerate(metric_classes, 1):\n","            metric_name = MetricClass.__name__.lower().replace('metric', '')\n","            print(f\"\\nProcessing metric [{i}/{len(metric_classes)}]: {metric_name}\")\n","            \n","            # Get the last processed epoch/height for this specific metric\n","            last_epoch_query = f\"\"\"\n","            SELECT MAX(epoch) as last_processed_epoch\n","            FROM research_metrics\n","            WHERE topic_id = {0 if MetricClass == ValidatorRewardMetric else topic_id} \n","              AND metric_name = '{metric_name}'\n","              AND epoch >= 0;  -- Exclude special entries like the global lock\n","            \"\"\"\n","            last_epoch_df = db_manager.execute_query(last_epoch_query)\n","            last_processed_epoch = last_epoch_df.iloc[0]['last_processed_epoch']\n","            min_block_height = 0\n","\n","            if last_processed_epoch is None:\n","                metric_min_block_height = min_block_height\n","                print(f\"  [{i}/{len(metric_classes)}] No previous data for {metric_name}\")\n","            else:\n","                last_processed_epoch = int(last_processed_epoch)\n","                # Handle ValidatorRewardMetric differently\n","                if MetricClass == ValidatorRewardMetric:\n","                    metric_min_block_height = last_processed_epoch + 1  # Use direct block height\n","                else:\n","                    metric_min_block_height = (last_processed_epoch + 1) * epoch_length\n","                print(f\"  [{i}/{len(metric_classes)}] {metric_name}:\")\n","                print(f\"    Last processed epoch: {last_processed_epoch}\")\n","                print(f\"    Starting calculation from block height: {metric_min_block_height}\")\n","\n","            # Create the metric instance with appropriate topic_id\n","            metric = MetricClass(\n","                metric_name, \n","                0 if MetricClass == ValidatorRewardMetric else topic_id,  # Use topic 0 for validator metric\n","                epoch_length\n","            )\n","            \n","            # Create the metric instance and calculate\n","            metric_data = metric.calculate(db_manager, metric_min_block_height)\n","\n","            if not metric_data.empty:\n","                print(f\"  [{i}/{len(metric_classes)}] {metric_name} calculation complete:\")\n","                print(f\"    Epochs: {metric_data['epoch'].min()} to {metric_data['epoch'].max()}\")\n","                print(f\"    Block heights: {metric_data['epoch'].min() * epoch_length} to {metric_data['epoch'].max() * epoch_length}\")\n","                print(f\"    Number of new records: {len(metric_data)}\")\n","\n","                # Ensure the DataFrame has only the expected columns and data types\n","                expected_columns = {\n","                    'topic_id': 'int64',\n","                    'epoch': 'int64',\n","                    'address': 'object',\n","                    'metric_value': 'float64',\n","                    'metric_name': 'object',\n","                    'updated_at': 'datetime64[ns, UTC]'\n","                }\n","                \n","                # Select only the expected columns and convert data types\n","                metric_data = metric_data[list(expected_columns.keys())]\n","                for col, dtype in expected_columns.items():\n","                    if col == 'address':\n","                        metric_data[col] = metric_data[col].astype(str)\n","                    else:\n","                        metric_data[col] = metric_data[col].astype(dtype)\n","\n","                # Remove any remaining null values\n","                metric_data = metric_data.dropna(subset=['metric_value'])\n","\n","                if not metric_data.empty:\n","                    db_manager.insert_metrics(metric_data)\n","                    print(f\"  [{i}/{len(metric_classes)}] Successfully inserted new data for {metric_name}\")\n","                else:\n","                    print(f\"  [{i}/{len(metric_classes)}] No new non-null data to insert for {metric_name}\")\n","            else:\n","                print(f\"  [{i}/{len(metric_classes)}] No new data calculated for {metric_name}\")\n","\n","            print(f\"Completed processing metric [{i}/{len(metric_classes)}]: {metric_name}\")\n","            print(\"-------------------------------------------\")\n","\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","    finally:\n","        db_manager.remove_global_lock()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["db_manager = DatabaseManager(db_config, db_config)\n","db_manager.connect()\n","\n","try:\n","    # Ensure the table is created in the write database before any operations\n","    db_manager.create_metrics_table()\n","    \n","    # Get all topics\n","    topics_query = \"SELECT id FROM topics ORDER BY id;\"\n","    topics_df = db_manager.execute_query(topics_query)\n","    \n","    if topics_df.empty:\n","        print(\"No topics found in the database.\")\n","    else:\n","        total_topics = len(topics_df)\n","        print(f\"Found {total_topics} topics to process\")\n","        \n","        # Process each topic\n","        for index, row in topics_df.iterrows():\n","            topic_id_ = int(row['id'])\n","            print(f\"\\nProcessing topic {topic_id_} [{index + 1}/{total_topics}]\")\n","            print(\"=\" * 50)\n","            \n","            try:\n","                update_specific_topic(db_manager, topic_id_)\n","                print(f\"Successfully processed topic {topic_id_}\")\n","            except Exception as e:\n","                print(f\"Error processing topic {topic_id_}: {e}\")\n","                continue\n","            \n","            print(\"=\" * 50)\n","            print(f\"Completed topic {topic_id_} [{index + 1}/{total_topics}]\")\n","        \n","        print(\"\\nAll topics have been processed!\")\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")\n","finally:\n","    db_manager.close()\n"]},{"cell_type":"code","execution_count":929,"metadata":{},"outputs":[],"source":["import json as _hex_json\n","\n"]},{"cell_type":"code","execution_count":930,"metadata":{},"outputs":[],"source":["import json as _hex_json\n","\n"]},{"cell_type":"code","execution_count":931,"metadata":{},"outputs":[],"source":["import json as _hex_json\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## ALL of the queries!"]},{"cell_type":"markdown","metadata":{},"source":["### info queries"]},{"cell_type":"code","execution_count":932,"metadata":{},"outputs":[],"source":["# Create SQLAlchemy engine\n","engine = create_engine(f\"postgresql://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\")\n","\n","# Query for last epoch info\n","raw_query = \"\"\"\n","    SELECT epoch, updated_at\n","    FROM research_metrics\n","    WHERE topic_id = {{topic_id}}\n","    ORDER BY epoch DESC\n","    LIMIT 1;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","last_epoch_df = pd.read_sql_query(sql_query, engine)\n","\n","# Query for max height info\n","raw_query = \"\"\"\n","    SELECT height, block_time\n","    FROM block_info\n","    WHERE height = (\n","        SELECT MAX(height)\n","        FROM block_info\n","    );\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","max_height_df = pd.read_sql_query(sql_query, engine)\n","\n","# Query for epoch length\n","raw_query = \"\"\"\n","    SELECT epoch_length\n","    FROM topics\n","    WHERE id={{topic_id}}\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","epoch_length_df = pd.read_sql_query(sql_query, engine)\n","\n","# Query for min epoch\n","raw_query = \"\"\"\n","    SELECT min(epoch)\n","    FROM research_metrics\n","    WHERE topic_id={{topic_id}}\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","min_epoch_df = pd.read_sql_query(sql_query, engine)\n","\n","# Query for metadata\n","raw_query = \"\"\"\n","    SELECT metadata\n","    FROM topics\n","    WHERE id={{topic_id}}\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","metadata_df = pd.read_sql_query(sql_query, engine)\n","\n","# Calculate derived values\n","last_epoch = last_epoch_df.values[0][0]\n","last_timestamp = last_epoch_df.values[0][1]\n","max_height = max_height_df.values[0][0]\n","max_timestamp = max_height_df.values[0][1]\n","epoch_length = int(epoch_length_df.values[0][0])\n","min_epoch = int(min_epoch_df.values[0][0])\n","topic_metadata = metadata_df.values[0][0]\n","lookback_height = max_height - lookback_epochs * epoch_length\n","min_height_to_lookback = max(lookback_height, min_epoch*epoch_length)\n"]},{"cell_type":"code","execution_count":933,"metadata":{},"outputs":[],"source":["last_epoch=last_epoch_df.values[0][0]\n","last_timestamp=last_epoch_df.values[0][1]\n","max_height = max_height_df.values[0][0]\n","max_timestamp = max_height_df.values[0][1]\n","epoch_length = int(epoch_length_df.values[0][0])\n","min_epoch = int(min_epoch_df.values[0][0])\n","topic_metadata = metadata_df.values[0][0]\n","lookback_height = max_height - lookback_epochs * epoch_length\n","min_height_to_lookback = max(lookback_height, min_epoch*epoch_length)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(min_height_to_lookback)"]},{"cell_type":"code","execution_count":935,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    WITH ranked_epochs AS (\n","        SELECT \n","            topic_id,\n","            epoch,\n","            COUNT(*) as inferrerlosses_count,\n","            ROW_NUMBER() OVER (PARTITION BY topic_id ORDER BY epoch DESC) as epoch_rank\n","        FROM \n","            research_metrics\n","        WHERE \n","            topic_id = {{topic_id}}\n","            AND metric_name = 'infererlosses'\n","        GROUP BY\n","            topic_id, epoch\n","    )\n","    SELECT \n","        topic_id,\n","        epoch,\n","        inferrerlosses_count\n","    FROM \n","        ranked_epochs\n","    WHERE \n","        epoch_rank <= {{lookback_epochs}}\n","    ORDER BY\n","        epoch DESC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","num_active_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":936,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        epoch,\n","        metric_value,\n","        metric_name\n","    FROM \n","        research_metrics\n","    WHERE \n","        topic_id = {{topic_id}} \n","        AND metric_name = 'naive_losses'\n","        AND epoch > (\n","            SELECT MAX(epoch) - {{lookback_epochs}}\n","            FROM research_metrics\n","            WHERE topic_id = {{topic_id}} AND metric_name = 'infererlosses'\n","        )\n","    ORDER BY\n","        epoch DESC;\n","    \n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","dataframe_5 = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":937,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        epoch,\n","        metric_value,\n","        metric_name\n","    FROM \n","        research_metrics\n","    WHERE \n","        topic_id = {{topic_id}} \n","        AND metric_name = 'combined_losses'\n","        AND epoch > (\n","            SELECT MAX(epoch) - {{lookback_epochs}}\n","            FROM research_metrics\n","            WHERE topic_id = {{topic_id}} AND metric_name = 'infererlosses'\n","        )\n","    ORDER BY\n","        epoch DESC;\n","    \n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","dataframe_6 = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":938,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        epoch,\n","        metric_value\n","    FROM \n","        research_metrics\n","    WHERE \n","        topic_id = {{topic_id}} \n","        AND metric_name = 'infererlosses'\n","        AND epoch > (\n","            SELECT MAX(epoch) - {{lookback_epochs}}\n","            FROM research_metrics\n","            WHERE topic_id = {{topic_id}} AND metric_name = 'infererlosses'\n","        )\n","    ORDER BY\n","        epoch DESC;\n","    \n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","dataframe_3 = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":939,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        epoch,\n","        metric_value\n","    FROM \n","        research_metrics\n","    WHERE \n","        topic_id = {{topic_id}} \n","        AND metric_name = 'forecasterlosses'\n","        AND epoch > (\n","            SELECT MAX(epoch) - {{lookback_epochs}}\n","            FROM research_metrics\n","            WHERE topic_id = {{topic_id}} AND metric_name = 'forecasterlosses'\n","        )\n","    ORDER BY\n","        epoch DESC;\n","    \n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","dataframe_4 = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":940,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        epoch,\n","        metric_name,\n","        address,\n","        metric_value\n","    FROM \n","        research_metrics\n","    WHERE \n","        topic_id = {{topic_id}} \n","        AND metric_name IN ('rawinfererreward', 'rawreputerreward', 'rawforecasterreward')  -- List of metric names\n","        AND epoch > (\n","            SELECT MAX(epoch) - {{lookback_epochs}}\n","            FROM research_metrics\n","            WHERE topic_id = {{topic_id}} AND metric_name = 'rawreputerreward'\n","        )\n","    ORDER BY\n","        epoch DESC, \n","        metric_name;  -- Order by epoch and metric_name\n","    \n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","raw_rewards_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":941,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        epoch,\n","        metric_name,\n","        address,\n","        metric_value\n","    FROM \n","        research_metrics\n","    WHERE \n","        topic_id = {{topic_id}}\n","        AND metric_name IN ('rawinfererscore', 'rawreputerscore', 'rawforecasterscore')  -- List of metric names\n","        AND epoch > (\n","            SELECT MAX(epoch) - {{lookback_epochs}}\n","            FROM research_metrics\n","            WHERE topic_id = {{topic_id}}  AND metric_name = 'infererlosses'\n","        )\n","    ORDER BY\n","        epoch DESC, \n","        metric_name;  -- Order by epoch and metric_name\n","    \n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","raw_score_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":942,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        epoch,\n","        metric_name,\n","        address,\n","        metric_value\n","    FROM \n","        research_metrics\n","    WHERE \n","        topic_id = {{topic_id}} \n","        AND metric_name IN ('rawforecasts', 'infererlosses')  -- List of metric names\n","        AND epoch > (\n","            SELECT MAX(epoch) - {{lookback_epochs}}\n","            FROM research_metrics\n","            WHERE topic_id = {{topic_id}} AND metric_name = 'infererlosses'\n","        )\n","    ORDER BY\n","        epoch DESC, \n","        metric_name;  -- Order by epoch and metric_name\n","    \n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","raw_fore_inf_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":943,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        epoch,\n","        metric_name,\n","        address,\n","        metric_value\n","    FROM \n","        research_metrics\n","    WHERE \n","        topic_id = {{topic_id}} \n","        AND metric_name IN ('raw_inference', 'infererlosses')  -- List of metric names\n","        AND epoch > (\n","            SELECT MAX(epoch) - {{lookback_epochs}}\n","            FROM research_metrics\n","            WHERE topic_id = {{topic_id}} AND metric_name = 'infererlosses'\n","        )\n","    ORDER BY\n","        epoch DESC, \n","        metric_name;  -- Order by epoch and metric_name\n","    \n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","raw_inf_loss_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":944,"metadata":{},"outputs":[],"source":["# print(raw_inf_loss_df['epoch'].max()*epoch_length)\n","# print(raw_inf_loss_df['epoch'])\n","max_height_for_nw_inference = raw_inf_loss_df['epoch'].max()*epoch_length"]},{"cell_type":"code","execution_count":945,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    WITH RankedInferences AS (\n","        SELECT \n","            (metadata->>'block_height')::int AS block_height,\n","            (metadata->>'block_height')::int / {{epoch_length}} AS epoch,\n","            (value->'network_inferences'->>'naive_value')::numeric AS naive_value,\n","            (value->'network_inferences'->>'combined_value')::numeric AS combined_value,\n","            value->'network_inferences'->'inferer_values' as inferer_values,\n","            ROW_NUMBER() OVER (PARTITION BY (metadata->>'block_height')::int / {{epoch_length}} ORDER BY (metadata->>'block_height')::int ASC) as rn\n","        FROM \n","            query_results\n","        WHERE \n","            query_type = 'network_inferences'\n","            AND (metadata->>'topic_id')::int = {{topic_id}}\n","            AND (metadata->>'block_height')::int > {{min_height_to_lookback}}\n","            AND (metadata->>'block_height')::int <= {{max_height_for_nw_inference}}\n","    )\n","    SELECT \n","        block_height,\n","        epoch,\n","        naive_value,\n","        combined_value,\n","        inferer_values\n","    FROM \n","        RankedInferences\n","    WHERE \n","        rn = 1\n","    ORDER BY \n","        block_height ASC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","nw_inference_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":946,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    WITH RankedInferences AS (\n","        SELECT \n","            (metadata->>'block_height')::int AS block_height,\n","            (metadata->>'block_height')::int / {{epoch_length}} AS epoch,\n","            (value->'network_inferences'->>'naive_value')::numeric AS naive_value,\n","            (value->'network_inferences'->>'combined_value')::numeric AS combined_value,\n","            value->'network_inferences'->'inferer_values' as inferer_values,\n","            ROW_NUMBER() OVER (PARTITION BY (metadata->>'block_height')::int / {{epoch_length}} ORDER BY (metadata->>'block_height')::int ASC) as rn\n","        FROM \n","            query_results\n","        WHERE \n","            key = 'latest_network_inferences_outlier_resistant_' || {{topic_id}}\n","            AND (metadata->>'block_height')::int > {{min_height_to_lookback}}\n","            AND (metadata->>'block_height')::int <= {{max_height_for_nw_inference}}\n","    )\n","    SELECT \n","        block_height,\n","        epoch,\n","        naive_value,\n","        combined_value,\n","        inferer_values\n","    FROM \n","        RankedInferences\n","    WHERE \n","        rn = 1\n","    ORDER BY \n","        block_height ASC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","nw_inference_outlier_res_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":947,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    WITH RankedCoefficients AS (\n","        SELECT \n","            block_height,\n","            block_height / {{epoch_length}} as epoch,\n","            addresses,\n","            coefficients,\n","            ROW_NUMBER() OVER (PARTITION BY block_height / {{epoch_length}} ORDER BY block_height ASC) as rn\n","        FROM \n","            listening_coefficients\n","        WHERE \n","            topic_id = {{topic_id}}\n","            AND actor_type = 'ACTOR_TYPE_REPUTER'\n","            AND block_height > {{min_height_to_lookback}}\n","    )\n","    SELECT \n","        block_height,\n","        epoch,\n","        addresses,\n","        coefficients\n","    FROM \n","        RankedCoefficients\n","    WHERE \n","        rn = 1\n","    ORDER BY \n","        block_height ASC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","listening_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":948,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    WITH EpochData AS (\n","        SELECT \n","            height,\n","            height / {{epoch_length}} as epoch,\n","            COUNT(*) as total_participants,\n","            COUNT(CASE WHEN is_active = true THEN 1 END) as active_participants,\n","            array_agg(DISTINCT CASE WHEN is_active = true THEN address END) as active_addresses\n","        FROM ema_scores\n","        WHERE topic_id = {{topic_id}}\n","        AND type = 'ACTOR_TYPE_INFERER_UNSPECIFIED'\n","        AND height > {{min_height_to_lookback}}\n","        GROUP BY height\n","    ),\n","    EpochSummary AS (\n","        SELECT \n","            epoch,\n","            MIN(height) as epoch_height,\n","            MAX(total_participants) as total_participants,\n","            MAX(active_participants) as active_participants,\n","            LAG(array_agg(active_addresses)) OVER (ORDER BY epoch) as prev_addresses,\n","            array_agg(active_addresses) as current_addresses\n","        FROM EpochData\n","        GROUP BY epoch\n","    )\n","    SELECT \n","        epoch,\n","        epoch_height as height,\n","        total_participants,\n","        active_participants,\n","        COALESCE(\n","            CARDINALITY(\n","                ARRAY(\n","                    SELECT UNNEST(current_addresses) \n","                    EXCEPT \n","                    SELECT UNNEST(prev_addresses)\n","                )\n","            ),\n","            CARDINALITY(ARRAY(SELECT UNNEST(current_addresses)))\n","        ) as new_addresses\n","    FROM EpochSummary\n","    ORDER BY epoch ASC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","new_ema_scores_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":949,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    WITH RankedInferences AS (\n","        SELECT \n","            (metadata->>'block_height')::int AS block_height,\n","            (metadata->>'block_height')::int / {{epoch_length}} AS epoch,\n","            (value->'network_inferences'->>'naive_value')::numeric AS naive_value,\n","            (value->'network_inferences'->'inferer_values')::jsonb AS inferer_values,  -- Changed to jsonb\n","            (value->'network_inferences'->>'combined_value')::numeric AS combined_value,\n","            (value->>'confidence_interval_values')::jsonb AS confidence_interval_values,\n","            (value->>'confidence_interval_raw_percentiles')::jsonb AS confidence_interval_percentiles,\n","            ROW_NUMBER() OVER (PARTITION BY (metadata->>'block_height')::int / {{epoch_length}} ORDER BY (metadata->>'block_height')::int ASC) as rn\n","        FROM \n","            query_results\n","        WHERE \n","            query_type = 'network_inferences'\n","            AND (metadata->>'topic_id')::int = {{topic_id}}\n","            AND (metadata->>'block_height')::int > {{min_height_to_lookback}}\n","            AND (metadata->>'block_height')::int <= {{max_height_for_nw_inference}}\n","    )\n","    SELECT \n","        block_height,\n","        epoch,\n","        naive_value,\n","        inferer_values,\n","        combined_value,\n","        confidence_interval_values,\n","        confidence_interval_percentiles\n","    FROM \n","        RankedInferences\n","    WHERE \n","        rn = 1\n","    ORDER BY \n","        block_height ASC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","ci_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":950,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    WITH RankedStakes AS (\n","        SELECT \n","            (metadata->>'block_height')::int AS block_height,\n","            (metadata->>'block_height')::int / {{epoch_length}} AS epoch,\n","            value::jsonb AS stakes_array,\n","            ROW_NUMBER() OVER (PARTITION BY (metadata->>'block_height')::int / {{epoch_length}} ORDER BY (metadata->>'block_height')::int ASC) as rn\n","        FROM \n","            query_results\n","        WHERE \n","            key = 'active_reputer_stakes_1'\n","            AND (metadata->>'block_height')::int > {{lookback_height}}\n","    )\n","    SELECT \n","        block_height,\n","        epoch,\n","        stakes_array\n","    FROM \n","        RankedStakes\n","    WHERE \n","        rn = 1\n","    ORDER BY \n","        block_height ASC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","stakes_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":951,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    WITH PayloadCount AS (\n","        SELECT \n","            reputer_nonce_block_height,\n","            reputer_nonce_block_height / {{epoch_length}} AS epoch,\n","            COUNT(*) AS payload_count\n","        FROM \n","            reputer_payload\n","        WHERE \n","            topic_id = {{topic_id}}\n","            AND reputer_nonce_block_height > {{min_height_to_lookback}}\n","        GROUP BY \n","            reputer_nonce_block_height\n","    )\n","    SELECT \n","        reputer_nonce_block_height,\n","        epoch,\n","        payload_count\n","    FROM \n","        PayloadCount\n","    ORDER BY \n","        reputer_nonce_block_height DESC;\n","    \n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","reputer_payload_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":952,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    WITH RankedInferences AS (\n","        SELECT \n","            (metadata->>'block_height')::int AS block_height,\n","            (metadata->>'block_height')::int / {{epoch_length}} AS epoch,\n","            (value->>'inferer_weights')::jsonb AS inferer_weights,\n","            (value->>'forecaster_weights')::jsonb AS forecaster_weights,\n","            ROW_NUMBER() OVER (PARTITION BY (metadata->>'block_height')::int / {{epoch_length}} ORDER BY (metadata->>'block_height')::int ASC) as rn\n","        FROM \n","            query_results\n","        WHERE \n","            query_type = 'network_inferences'\n","            AND (metadata->>'topic_id')::int = {{topic_id}}\n","            AND (metadata->>'block_height')::int > {{lookback_height}}\n","    )\n","    SELECT \n","        block_height,\n","        epoch,\n","        inferer_weights,\n","        forecaster_weights\n","    FROM \n","        RankedInferences\n","    WHERE \n","        rn = 1\n","    ORDER BY \n","        block_height ASC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","weights_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":953,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT DISTINCT\n","        block_height,\n","        block_height / {{epoch_length}} as epoch,\n","        addresses,\n","        regrets\n","    FROM \n","        naive_inferer_network_regret\n","    WHERE \n","        topic_id = {{topic_id}}\n","        AND block_height > {{lookback_height}}\n","    ORDER BY \n","        block_height DESC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","naive_regret_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":954,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT DISTINCT\n","        block_height,\n","        block_height / {{epoch_length}} as epoch,\n","        addresses,\n","        regrets\n","    FROM \n","        inferer_network_regret\n","    WHERE \n","        topic_id = {{topic_id}}\n","        AND block_height > {{lookback_height}}\n","    ORDER BY \n","        block_height DESC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","nw_inf_regret_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":955,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT DISTINCT\n","        block_height,\n","        block_height / {{epoch_length}} as epoch,\n","        addresses,\n","        regrets\n","    FROM \n","        forecaster_network_regret\n","    WHERE \n","        topic_id = {{topic_id}}\n","        AND block_height > {{lookback_height}}\n","    ORDER BY \n","        block_height DESC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","forecast_regret_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":956,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        block_height,\n","        block_height / {{epoch_length}} as epoch,\n","        regret\n","    FROM \n","        topic_initial_regret\n","    WHERE \n","        topic_id = {{topic_id}}\n","        AND block_height > {{lookback_height}}\n","    ORDER BY \n","        block_height ASC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","init_regret_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":957,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        CAST(value->>'block_height_target_e_i_last_calculated' AS DOUBLE PRECISION) AS last_height_update,\n","        CAST(value->>'ecosystem_mint_supply_remaining' AS NUMERIC) / POWER(10, 18) AS ecosystem_mint_supply_remaining,\n","        (metadata->>'block_height')::int AS block_height,\n","        CAST(value->>'block_height_target_e_i_next_calculated' AS DOUBLE PRECISION) AS next_height_update,\n","        CAST(value->>'previous_block_emission' AS DOUBLE PRECISION) / POWER(10, 18) AS previous_block_emission,\n","        CAST(value->>'previous_reward_emission_per_unit_staked_token' AS DOUBLE PRECISION) AS previous_reward_emission_per_unit_staked_token,\n","        CAST(value->>'blocks_per_month' AS DOUBLE PRECISION) AS blocks_per_month,\n","        CAST(value->>'target_emission_rate_per_unit_staked_token' AS DOUBLE PRECISION) AS target_emission_rate_per_unit_staked_token,\n","        CAST(value->>'network_staked_tokens' AS DOUBLE PRECISION) AS network_staked,\n","        CAST(value->>'emission_per_unit_staked_token' AS DOUBLE PRECISION) AS emission_per_unit_staked_token,\n","        CAST(value->>'locked_vesting_tokens_investors_preseed' AS NUMERIC) / POWER(10, 18) AS investors_preseed_locked,\n","        CAST(value->>'ecosystem_locked' AS NUMERIC) / POWER(10, 18) AS ecosystem_locked,\n","        CAST(value->>'locked_vesting_tokens_total' AS NUMERIC) / POWER(10, 18) AS total_locked,\n","        CAST(value->>'locked_vesting_tokens_team' AS NUMERIC) / POWER(10, 18) AS team_locked,\n","        CAST(value->>'circulating_supply' AS NUMERIC) / POWER(10, 18) AS circulating_supply,\n","        CAST(value->>'max_supply' AS NUMERIC) / POWER(10, 18) AS max_supply\n","    \n","    \n","    \n","        \n","    FROM \n","        query_results\n","    WHERE \n","        query_type = 'emission_info'\n","        AND (metadata->>'block_height')::int = (\n","            SELECT MAX((metadata->>'block_height')::int)\n","            FROM query_results\n","            WHERE query_type = 'emission_info'\n","        );\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","current_token_details = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":958,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        (metadata->>'block_height')::int AS block_height,\n","        CAST(value->>'ecosystem_mint_supply_remaining' AS NUMERIC) / POWER(10, 18) AS ecosystem_mint_supply_remaining,\n","        CAST(value->>'ecosystem_balance' AS NUMERIC) / POWER(10, 18) AS ecosystem_balance,\n","        CAST(value->>'network_staked_tokens' AS NUMERIC) / POWER(10, 18) AS network_staked,\n","        CAST(value->>'circulating_supply' AS NUMERIC) / POWER(10, 18) AS circulating_supply,\n","        CAST(value->>'target_reward_emission_per_unit_staked_token' AS NUMERIC) AS target_reward_emission_per_unit_staked_token,\n","        CAST(value->>'block_emission' AS NUMERIC)/ POWER(10, 18) AS block_emission,\n","        CAST(value->>'emission_per_unit_staked_token' AS NUMERIC)/ POWER(10, 18) AS emission_per_unit_staked_token,\n","        CAST(value->>'previous_block_emission' AS DOUBLE PRECISION)/ POWER(10, 18) AS previous_emission,\n","        CAST(value->>'previous_reward_emission_per_unit_staked_token' AS DOUBLE PRECISION) AS previous_reward_emission_per_unit_staked_token,\n","        CAST(value->>'max_supply' AS DOUBLE PRECISION) / POWER(10, 18) AS max_supply    \n","    FROM \n","        query_results\n","    WHERE \n","        query_type = 'emission_info'\n","        AND (metadata->>'block_height')::int > {{max_height-lookback_blocks}}\n","    ORDER BY \n","        block_height ASC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","new_supply_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":959,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        (metadata->>'block_height')::int AS block_height,\n","        CAST(value->>'locked_vesting_tokens_investors_seed' AS NUMERIC) / POWER(10, 18) AS investors_seed_locked,\n","        CAST(value->>'locked_vesting_tokens_investors_preseed' AS NUMERIC) / POWER(10, 18) AS investors_preseed_locked,\n","        CAST(value->>'ecosystem_locked' AS NUMERIC) / POWER(10, 18) AS ecosystem_locked,\n","        CAST(value->>'locked_vesting_tokens_total' AS NUMERIC) / POWER(10, 18) AS total_locked,\n","        CAST(value->>'locked_vesting_tokens_team' AS NUMERIC) / POWER(10, 18) AS team_locked\n","    FROM \n","        query_results\n","    WHERE \n","        query_type = 'emission_info'\n","        AND (metadata->>'block_height')::int > {{max_height-lookback_blocks}}\n","    ORDER BY \n","        block_height ASC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","locked_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":960,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        epoch AS block_height,\n","        metric_value as normalized_amount\n","    FROM \n","        research_metrics\n","    WHERE\n","        epoch >= {{max_height-lookback_blocks}} AND metric_name='validatorreward'\n","    ORDER BY \n","        epoch ASC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","validator_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":961,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    WITH summed_rewards AS (\n","        SELECT \n","            validator,\n","            SUM(amount::decimal / POWER(10, 18)) as total_rewards\n","        FROM \n","            validator_rewards\n","        WHERE \n","            height_tx >= {{max_height-lookback_blocks}}\n","        GROUP BY \n","            validator\n","    )\n","    SELECT \n","        validator,\n","        total_rewards,\n","        total_rewards / SUM(total_rewards) OVER () as normalized_rewards\n","    FROM \n","        summed_rewards\n","    ORDER BY \n","        total_rewards DESC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","v_rewards_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":962,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    WITH recent_epochs AS (\n","        SELECT DISTINCT epoch\n","        FROM research_metrics\n","        WHERE topic_id = {{topic_id}}\n","        ORDER BY epoch DESC\n","        LIMIT {{lookback_epochs}}\n","    ),\n","    epoch_blocks AS (\n","        SELECT epoch, epoch * {{epoch_length}} AS block_height\n","        FROM recent_epochs\n","    )\n","    SELECT \n","        eb.epoch,\n","        eb.block_height,\n","        bi.block_time\n","    FROM epoch_blocks eb\n","    LEFT JOIN block_info bi ON bi.height = eb.block_height\n","    ORDER BY eb.block_height DESC;\n","    \n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","time_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":963,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    SELECT \n","        FLOOR(height / {{epoch_length}}) as epoch,\n","        height as block_height,\n","        block_time\n","    FROM block_info\n","    WHERE height >= {{min_height_to_lookback}}\n","    ORDER BY height DESC;\n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","new_time_df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":964,"metadata":{},"outputs":[],"source":["import jinja2\n","raw_query = \"\"\"\n","    WITH recent_epochs AS (\n","        SELECT DISTINCT epoch\n","        FROM research_metrics\n","        WHERE topic_id = {{topic_id}}\n","        ORDER BY epoch DESC\n","        LIMIT {{lookback_epochs}}\n","    )\n","    SELECT \n","        rm.topic_id,\n","        rm.metric_name,\n","        rm.epoch,\n","        rm.address,\n","        rm.metric_value\n","    FROM \n","        research_metrics rm\n","    JOIN \n","        recent_epochs re\n","    ON \n","        rm.epoch = re.epoch\n","    WHERE \n","        rm.topic_id = {{topic_id}}\n","    ORDER BY \n","        rm.epoch DESC;\n","    \n","\"\"\"\n","sql_query = jinja2.Template(raw_query).render(vars())\n","df = pd.read_sql_query(sql_query, engine)"]},{"cell_type":"code","execution_count":965,"metadata":{},"outputs":[],"source":["# First, let's explode the inferer weights into separate rows\n","def extract_weights(row):\n","    # No need for json.loads since the data is already a list\n","    weights = row['inferer_weights']\n","    return pd.DataFrame(weights)\n","\n","# Create expanded dataframe with weights\n","weights_expanded = pd.DataFrame()\n","for idx, row in weights_df.iterrows():\n","    df_temp = extract_weights(row)\n","    df_temp['epoch'] = row['epoch']\n","    df_temp['block_height'] = row['block_height']\n","    weights_expanded = pd.concat([weights_expanded, df_temp])\n","\n","# Convert weight column to numeric\n","weights_expanded['weight'] = pd.to_numeric(weights_expanded['weight'])\n","\n","# Create rows for each address-regret pair\n","regrets_expanded = []\n","for _, row in nw_inf_regret_df.iterrows():\n","    # Skip rows where addresses or regrets are None\n","    if row['addresses'] is not None and row['regrets'] is not None:\n","        try:\n","            for addr, regret in zip(row['addresses'], row['regrets']):\n","                regrets_expanded.append({\n","                    'epoch': row['epoch'],\n","                    'addresses': addr,\n","                    'regrets': regret\n","                })\n","        except Exception as e:\n","            print(f\"Error processing row with epoch {row['epoch']}: {e}\")\n","            print(\"Row data:\", row)\n","            continue\n","\n","regrets_expanded = pd.DataFrame(regrets_expanded)\n","\n","\n","# Merge weights and regrets on epoch and address\n","worker_performance = pd.merge(\n","    weights_expanded,\n","    regrets_expanded,\n","    left_on=['epoch', 'worker'],\n","    right_on=['epoch', 'addresses'],\n","    how='inner'\n",")\n","\n","# Sort by epoch and weight\n","worker_performance = worker_performance.sort_values(['epoch', 'weight'], ascending=[True, False])"]},{"cell_type":"markdown","metadata":{},"source":["# Ground truth interpolation"]},{"cell_type":"markdown","metadata":{},"source":["assuming MSE"]},{"cell_type":"code","execution_count":966,"metadata":{},"outputs":[],"source":["# Pivot the DataFrame to create separate columns for raw_inference and infererlosses\n","restructured_df = raw_inf_loss_df.pivot(\n","    index=['epoch', 'address'],\n","    columns='metric_name',\n","    values='metric_value'\n",").reset_index()\n","\n","# Rename the columns to be more intuitive\n","restructured_df = restructured_df.rename(columns={\n","    'raw_inference': 'inference',\n","    'infererlosses': 'loss'\n","})\n","\n","# Ensure the columns are in a nice order\n","restructured_df = restructured_df[['epoch', 'address', 'inference', 'loss']]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert values to numeric, handling any conversion errors\n","restructured_df['inference'] = pd.to_numeric(restructured_df['inference'], errors='coerce')\n","restructured_df['loss'] = pd.to_numeric(restructured_df['loss'], errors='coerce')\n","\n","# Drop rows with NaN values\n","clean_df = restructured_df.dropna(subset=['inference', 'loss'])\n","\n","# Calculate the plus/minus loss values\n","clean_df['inference_plus_loss'] = clean_df['inference'] + np.sqrt(clean_df['loss'])\n","clean_df['inference_minus_loss'] = clean_df['inference'] - np.sqrt(clean_df['loss'] )\n","\n","# Identify ground truth per epoch\n","ground_truths = []\n","for epoch, group in clean_df.groupby('epoch'):\n","    all_values = np.concatenate([\n","        group['inference_plus_loss'].round(5),\n","        group['inference_minus_loss'].round(5)\n","    ])\n","    unique, counts = np.unique(all_values, return_counts=True)\n","    ground_truth = unique[np.argmax(counts)]\n","    ground_truths.append((epoch, ground_truth))\n","\n","# Create DataFrame of ground truths\n","ground_truths_df = pd.DataFrame(ground_truths, columns=['epoch', 'ground_truth'])\n","ground_truths_df['ground_truth'] = -ground_truths_df['ground_truth']\n","\n","# Print some info about the data cleaning\n","print(f\"Original number of rows: {len(restructured_df)}\")\n","print(f\"Number of rows after dropping NaN: {len(clean_df)}\")\n","print(f\"Number of epochs with ground truth: {len(ground_truths_df)}\")\n","# plot the ground truths\n","fig = go.Figure()\n","fig.add_trace(go.Scatter(x=ground_truths_df['epoch'], y=ground_truths_df['ground_truth'], mode='lines+markers', name='Ground Truth'))\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Metrics"]},{"cell_type":"markdown","metadata":{},"source":["## Forecaster Health"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filter the DataFrame for the forecast_health metric\n","forecast_health_df = df[df['metric_name'] == 'forecasthealth'].copy()\n","\n","# Sort by 'epoch' to ensure correct EMA calculation\n","forecast_health_df = forecast_health_df.sort_values(by='epoch')\n","\n","# Compute the EMA (Exponential Moving Average)\n","alpha = 0.1  # Smoothing factor for the EMA\n","forecast_health_df['ema'] = forecast_health_df['metric_value'].ewm(alpha=alpha).mean()\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define Viridis color for the line\n","forecast_health_color = '#440154'  # Bright purple from Viridis\n","ema_color = 'red'  # Red color for EMA line\n","\n","# Add original forecast health metric line\n","fig.add_trace(go.Scatter(\n","    x=forecast_health_df['epoch'],\n","    y=forecast_health_df['metric_value'],\n","    mode='lines+markers',\n","    name='Forecast Health',\n","    line=dict(color=forecast_health_color),\n","    marker=dict(color=forecast_health_color),\n","    hovertemplate='Forecast Health: %{y:.2f}<extra></extra>'\n","))\n","\n","# Add EMA line\n","fig.add_trace(go.Scatter(\n","    x=forecast_health_df['epoch'],\n","    y=forecast_health_df['ema'],\n","    mode='lines',\n","    name=f'EMA',\n","    line=dict(color=ema_color),\n","    hovertemplate='EMA: %{y:.2f}<extra></extra>'\n","))\n","\n","# Update the layout with Viridis style settings\n","fig.update_layout(\n","    title=f\"Forecast Health Metric for Topic {forecast_health_df['topic_id'].iloc[0]}\",\n","    xaxis_title=\"Epoch\",\n","    yaxis_title=\"Forecast Health Value\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["- We are plotting the raw score of the entire forecasting task $$T_i$$\n","    - Equation 42 of the white paper\n","- A **large/postive** value is **healthy** and indicates that forecasters are helping topic {{topic_id}}! 😁✅\n","- A **small/negative** value is **unhealthy** and indicates that forecasters aren't really helping topic {{topic_id}}! 😢😷"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create scatter plot\n","fig = go.Figure()\n","\n","# Add small constant to weights to avoid log(0)\n","epsilon = 1e-10\n","log_weights = np.log10(worker_performance['weight'] + epsilon)\n","\n","# Add scatter trace\n","fig.add_trace(\n","    go.Scatter(\n","        x=worker_performance['regrets'],\n","        y=log_weights,\n","        mode='markers',\n","        marker=dict(\n","            size=8,\n","            opacity=0.6,\n","            color=worker_performance['epoch'],\n","            colorscale='Viridis',\n","            showscale=True,\n","            colorbar=dict(title='Epoch')\n","        ),\n","        hovertemplate=\n","        '<b>Address:</b> %{text}<br>' +\n","        '<b>Regret:</b> %{x:.4f}<br>' +\n","        '<b>Log Weight:</b> %{y:.4f}<br>' +\n","        '<b>Epoch:</b> %{marker.color}<br>' +\n","        '<extra></extra>',\n","        text=worker_performance['worker']\n","    )\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    title='Inferer Regret vs Log Weight',\n","    xaxis_title='Combined Regret',\n","    yaxis_title='Log(Weight)',\n","    template='plotly_white',\n","    height=600,\n","    width=800\n",")\n","\n","# Show plot\n","fig.show()\n","\n","# # Print some statistics about the weights\n","# print(\"\\nWeight statistics:\")\n","# print(f\"Min weight: {combined_performance['weight'].min()}\")\n","# print(f\"Max weight: {combined_performance['weight'].max()}\")\n","# print(f\"Number of zero weights: {(combined_performance['weight'] == 0).sum()}\")"]},{"cell_type":"markdown","metadata":{},"source":["### query to grab from the research table"]},{"cell_type":"code","execution_count":232,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":970,"metadata":{},"outputs":[],"source":["# # Convert timestamps to datetime UTC\n","# gt_df['timestamp'] = pd.to_datetime(gt_df['timestamp'])\n","\n","# # Merge using nearest timestamp matching\n","# ground_truths_df = pd.merge_asof(\n","#     gt_df.sort_values('timestamp'),\n","#     new_time_df[['block_time', 'epoch']].sort_values('block_time'),\n","#     left_on='timestamp',\n","#     right_on='block_time',\n","#     direction='nearest'\n","# )\n","\n","# # Drop duplicates keeping first occurrence of each epoch\n","# ground_truths_df = ground_truths_df.drop_duplicates(subset=['epoch'], keep='first')\n","# ground_truths_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the figure\n","fig = go.Figure()\n","\n","# Add ground truth trace\n","fig.add_trace(\n","    go.Scatter(\n","        x=ground_truths_df['epoch'],\n","        y=ground_truths_df['ground_truth'],\n","        mode='lines+markers',\n","        name='Ground Truth',\n","        line=dict(color='#3b528b'),\n","        marker=dict(size=4),\n","        hovertemplate='Ground Truth: %{y}<extra></extra>'\n","    )\n",")\n","\n","# Add naive value trace\n","fig.add_trace(\n","    go.Scatter(\n","        x=nw_inference_df['epoch'],\n","        y=nw_inference_df['naive_value'],\n","        mode='lines+markers',\n","        name='Naive Value',\n","        marker=dict(size=4),\n","        hovertemplate='Naive Value: %{y}<extra></extra>'\n","    )\n",")\n","\n","# Add combined value trace\n","fig.add_trace(\n","    go.Scatter(\n","        x=nw_inference_df['epoch'],\n","        y=nw_inference_df['combined_value'],\n","        mode='lines+markers',\n","        name='Combined Value',\n","        marker=dict(size=4),\n","        hovertemplate='Combined Value: %{y}<extra></extra>'\n","    )\n",")\n","\n","# Add outlier resistant values\n","fig.add_trace(\n","    go.Scatter(\n","        x=nw_inference_outlier_res_df['epoch'],\n","        y=nw_inference_outlier_res_df['combined_value'],\n","        mode='lines+markers',\n","        name='Outlier Resistant Combined Value',\n","        marker=dict(size=4),\n","        hovertemplate='Outlier Resistant Combined Value: %{y}<extra></extra>'\n","    )\n",")\n","fig.add_trace(\n","    go.Scatter(\n","        x=nw_inference_outlier_res_df['epoch'],\n","        y=nw_inference_outlier_res_df['naive_value'],\n","        mode='lines+markers',\n","        name='Outlier Resistant Naive Value',\n","        marker=dict(size=4),\n","        hovertemplate='Outlier Resistant Naive Value: %{y}<extra></extra>'\n","    )\n",")\n","\n","\n","\n","# Update layout\n","fig.update_layout(\n","    title='Network Inferences and Ground Truth by Epoch',\n","    xaxis_title='Epoch',\n","    yaxis_title='Value',\n","    height=500,\n","    width=800,\n","    template='plotly_white',\n","    hovermode='x unified',\n","    spikedistance=-1,\n","    showlegend=True,\n","    legend=dict(\n","        yanchor='top',\n","        y=1,\n","        xanchor='left',\n","        x=1.05\n","    ),\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash='dot',\n","        spikecolor='grey'\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash='dot',\n","        spikecolor='grey'\n","    ),\n","    hoverlabel=dict(\n","        bgcolor='rgba(255, 255, 255, 0.7)',\n","        bordercolor='rgba(0, 0, 0, 0)',\n","        font_size=12,\n","        font_family='Arial',\n","        namelength=-1\n","    )\n",")\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["flattened_inferences = []\n","for idx, row in nw_inference_df.iterrows():\n","    epoch = row['epoch']\n","    inferer_values = row['inferer_values'] if isinstance(row['inferer_values'], list) else json.loads(row['inferer_values'])\n","    for inferer in inferer_values:\n","        flattened_inferences.append({\n","            'epoch': epoch,\n","            'value': float(inferer['value']),\n","            'worker': inferer['worker']\n","        })\n","        \n","flattened_df = pd.DataFrame(flattened_inferences)\n","\n","fig = go.Figure()\n","\n","# Add all raw inferences (unchanged)\n","fig.add_trace(\n","    go.Scatter(\n","        x=flattened_df['epoch'],\n","        y=flattened_df['value'],\n","        mode='markers',\n","        marker=dict(\n","            size=3,\n","            color='gray',\n","            opacity=0.2\n","        ),\n","        name='Worker Inferences',\n","        hoverinfo='skip',\n","    )\n",")\n","\n","# Add ground truth trace shifted back by one epoch\n","fig.add_trace(\n","    go.Scatter(\n","        x=ground_truths_df['epoch'] - 1,  # Shift epoch back by 1\n","        y=ground_truths_df['ground_truth'],\n","        mode='lines+markers',\n","        name='Ground Truth',\n","        line=dict(color='#3b528b'),\n","        marker=dict(size=4),\n","        hovertemplate='Ground Truth: %{y}<extra></extra>'\n","    )\n",")\n","\n","# Add naive value trace (unchanged)\n","fig.add_trace(\n","    go.Scatter(\n","        x=nw_inference_df['epoch'],\n","        y=nw_inference_df['naive_value'],\n","        mode='lines+markers',\n","        name='Naive Value',\n","        marker=dict(size=4),\n","        hovertemplate='Naive Value: %{y}<extra></extra>'\n","    )\n",")\n","\n","# Add combined value trace (unchanged)\n","fig.add_trace(\n","    go.Scatter(\n","        x=nw_inference_df['epoch'],\n","        y=nw_inference_df['combined_value'],\n","        mode='lines+markers',\n","        name='Combined Value',\n","        marker=dict(size=4),\n","        hovertemplate='Combined Value: %{y}<extra></extra>'\n","    )\n",")\n","\n","# Add outlier resistant values\n","fig.add_trace(\n","    go.Scatter(\n","        x=nw_inference_outlier_res_df['epoch'],\n","        y=nw_inference_outlier_res_df['combined_value'],\n","        mode='lines+markers',\n","        name='Outlier Resistant Combined Value',\n","        marker=dict(size=4),\n","        hovertemplate='Outlier Resistant Combined Value: %{y}<extra></extra>'\n","    )\n",")\n","fig.add_trace(\n","    go.Scatter(\n","        x=nw_inference_outlier_res_df['epoch'],\n","        y=nw_inference_outlier_res_df['naive_value'],\n","        mode='lines+markers',\n","        name='Outlier Resistant Naive Value',\n","        marker=dict(size=4),\n","        hovertemplate='Outlier Resistant Naive Value: %{y}<extra></extra>'\n","    )\n",")\n","\n","\n","# Rest of the layout settings remain the same\n","fig.update_layout(\n","    title='Network Inferences and Ground Truth by Epoch',\n","    xaxis_title='Epoch',\n","    yaxis_title='Value',\n","    height=500,\n","    width=800,\n","    template='plotly_white',\n","    hovermode='x unified',\n","    spikedistance=-1,\n","    showlegend=True,\n","    legend=dict(\n","        yanchor='top',\n","        y=1,\n","        xanchor='left',\n","        x=1.05\n","    ),\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash='dot',\n","        spikecolor='grey'\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash='dot',\n","        spikecolor='grey'\n","    ),\n","    hoverlabel=dict(\n","        bgcolor='rgba(255, 255, 255, 0.7)',\n","        bordercolor='rgba(0, 0, 0, 0)',\n","        font_size=12,\n","        font_family='Arial',\n","        namelength=-1\n","    )\n",")\n","\n","fig.show()"]},{"cell_type":"code","execution_count":973,"metadata":{},"outputs":[],"source":["# merged_df = pd.merge(\n","#     ground_truths_df,\n","#     nw_inference_df[['epoch', 'naive_value', 'combined_value']],\n","#     on='epoch',\n","#     how='inner'\n","# )\n","\n","# # Create the scatter plot\n","# fig = go.Figure()\n","\n","# # Add scatter points for naive value vs ground truth\n","# fig.add_trace(go.Scatter(\n","#     x=merged_df['ground_truth'], \n","#     y=merged_df['naive_value'], \n","#     mode='markers',\n","#     marker=dict(size=8, color='#21918c'),\n","#     name='Naive Value',\n","#     text=merged_df['epoch'],\n","#     hovertemplate='<b>Naive Value:</b> %{y}<br><b>Ground Truth:</b> %{x}<br><b>Epoch:</b> %{text}<extra></extra>'\n","# ))\n","\n","# # Add scatter points for combined value vs ground truth\n","# fig.add_trace(go.Scatter(\n","#     x=merged_df['ground_truth'], \n","#     y=merged_df['combined_value'], \n","#     mode='markers',\n","#     marker=dict(size=8, color='#3b528b'),\n","#     name='Combined Value',\n","#     text=merged_df['epoch'],\n","#     hovertemplate='<b>Combined Value:</b> %{y}<br><b>Ground Truth:</b> %{x}<br><b>Epoch:</b> %{text}<extra></extra>'\n","# ))\n","\n","# # Calculate min and max values from merged data\n","# min_value = min(\n","#     merged_df['ground_truth'].min(),\n","#     merged_df['naive_value'].min(),\n","#     merged_df['combined_value'].min()\n","# )\n","# max_value = max(\n","#     merged_df['ground_truth'].max(),\n","#     merged_df['naive_value'].max(),\n","#     merged_df['combined_value'].max()\n","# )\n","\n","# # Add padding\n","# padding = (max_value - min_value) * 0.05\n","# min_value_with_padding = min_value - padding\n","# max_value_with_padding = max_value + padding\n","\n","# # Add y=x reference line\n","# fig.add_trace(go.Scatter(\n","#     x=[min_value_with_padding, max_value_with_padding],\n","#     y=[min_value_with_padding, max_value_with_padding],\n","#     mode='lines',\n","#     name='y=x',\n","#     line=dict(color='red', dash='dash')\n","# ))\n","\n","# # Update layout\n","# fig.update_layout(\n","#     xaxis_title='Ground Truth',\n","#     yaxis_title='Network Inference',\n","#     title='Network Inferences vs Ground Truth',\n","#     title_x=0.5,\n","#     height=800,\n","#     width=1000,\n","#     template=\"plotly_white\",\n","#     hovermode=\"closest\",\n","#     spikedistance=-1,\n","#     xaxis=dict(\n","#         showspikes=True,\n","#         spikemode='across',\n","#         spikesnap='cursor',\n","#         spikethickness=1,\n","#         showline=True,\n","#         showgrid=True,\n","#         spikedash=\"dot\",\n","#         spikecolor=\"grey\",\n","#         range=[min_value_with_padding, max_value_with_padding],\n","#         scaleanchor='y',\n","#         constrain='domain',\n","#     ),\n","#     yaxis=dict(\n","#         showspikes=True,\n","#         spikemode='across',\n","#         spikesnap='cursor',\n","#         spikethickness=1,\n","#         showline=True,\n","#         showgrid=True,\n","#         spikedash=\"dot\",\n","#         spikecolor=\"grey\",\n","#         range=[min_value_with_padding, max_value_with_padding],\n","#         scaleratio=1\n","#     ),\n","#     hoverlabel=dict(\n","#         bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","#         bordercolor=\"rgba(0, 0, 0, 0)\",\n","#         font=dict(\n","#             color='black',\n","#             size=12,\n","#             family=\"Arial\"\n","#         )\n","#     ),\n","#     showlegend=True,\n","#     legend=dict(\n","#         yanchor=\"top\",\n","#         y=0.99,\n","#         xanchor=\"left\",\n","#         x=1.05\n","#     )\n","# )\n","\n","# fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get the percentiles from the first row - already a list\n","percentiles = ci_df['confidence_interval_percentiles'].iloc[0]\n","percentile_labels = [f'{p}th percentile' for p in percentiles]\n","\n","# Create new figure for confidence intervals\n","fig_ci = go.Figure()\n","\n","# The values are already lists, no need for conversion\n","ci_values = ci_df['confidence_interval_values']\n","\n","# Check lengths\n","expected_length = len(percentiles)\n","for idx, values in enumerate(ci_values):\n","    if len(values) != expected_length:\n","        print(f\"Row {idx} has {len(values)} values, expected {expected_length}\")\n","\n","# Define colors\n","colors = ['red', 'orange', 'green', 'blue', 'purple']\n","\n","# Plot individual inferer values as blue X's\n","for idx, row in ci_df.iterrows():\n","    # inferer_values is already a list of dicts\n","    values = [float(val['value']) for val in row['inferer_values']]\n","    fig_ci.add_trace(\n","        go.Scatter(\n","            x=[row['epoch']] * len(values),\n","            y=values,\n","            mode='markers',\n","            name='Individual Inferences' if idx == 0 else None,\n","            marker=dict(symbol='x', size=8, color='blue', opacity=0.6),\n","            showlegend=(idx == 0)\n","        )\n","    )\n","\n","# Plot each confidence interval value with larger markers\n","for i in range(expected_length):\n","    fig_ci.add_trace(\n","        go.Scatter(\n","            x=ci_df['epoch'],\n","            y=[values[i] for values in ci_values],\n","            mode='markers',\n","            name=percentile_labels[i],\n","            marker=dict(color=colors[i], size=6)\n","        )\n","    )\n","\n","# Plot network inference as green plus\n","fig_ci.add_trace(\n","    go.Scatter(\n","        x=ci_df['epoch'],\n","        y=ci_df['combined_value'],\n","        mode='markers',\n","        name='Network Inference',\n","        marker=dict(symbol='cross', size=10, color='green', opacity=1)\n","    )\n",")\n","\n","# Update layout\n","fig_ci.update_layout(\n","    title='Inferences and Percentiles per Epoch',\n","    xaxis_title='Epoch',\n","    yaxis_title='Values',\n","    showlegend=True,\n","    legend=dict(yanchor=\"top\", y=1, xanchor=\"left\", x=1.05),\n","    template='plotly_white',\n","    height=800,\n","    width=1000\n",")\n","\n","# Add grid\n","fig_ci.update_xaxes(showgrid=True, gridwidth=1, gridcolor='rgba(0,0,0,0.2)')\n","\n","# Show plot\n","fig_ci.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Inferer Health"]},{"cell_type":"markdown","metadata":{},"source":["- We plot\n","    - $$\\log\\left(\\frac{\\text{MDM}}{\\text{MAE}}\\right)$$\n","    - where $$\\text{MDM}$$ is the mean absolute distance to the mean inference and $$\\text{MAE}$$ is the mean absolute error in the network combined inference\n","- A **large/positive** value is **healthy** and corresponds to the active set consisting of heterogenous inferers 😁✅\n","- A **small/negative** value is **unhealthy** and corresponds to the active set consisting of homogeneous inferers  😢😷"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filter the DataFrame for the inferer_health metric\n","inferer_health_df = df[df['metric_name'] == 'infererhealth']\n","inferer_health_df = inferer_health_df.sort_values(by='epoch')\n","\n","# Calculate EMA with alpha = 0.1\n","alpha = 0.1\n","ema_values = inferer_health_df['metric_value'].ewm(alpha=alpha).mean()\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define Viridis color for the Inferer Health line\n","forecast_health_color = '#fde725'  # Bright yellow from Viridis\n","\n","# Plot Inferer Health line\n","fig.add_trace(go.Scatter(\n","    x=inferer_health_df['epoch'],\n","    y=inferer_health_df['metric_value'],\n","    mode='lines+markers',\n","    name='Inferer Health',\n","    line=dict(color=forecast_health_color),\n","    marker=dict(color=forecast_health_color),\n","    hovertemplate='Inferer Health: %{y:.2f}<extra></extra>'\n","))\n","\n","# Add EMA line with red color\n","fig.add_trace(go.Scatter(\n","    x=inferer_health_df['epoch'],\n","    y=ema_values,\n","    mode='lines',\n","    name='EMA',\n","    line=dict(color='red', dash='solid', width=2),\n","    hovertemplate='EMA: %{y:.2f}<extra></extra>'\n","))\n","\n","# Update the layout with Viridis style settings\n","fig.update_layout(\n","    title=f\"Inferer Health Metric for Topic {inferer_health_df['topic_id'].iloc[0]}\",\n","    xaxis_title=\"Epoch\",\n","    yaxis_title=\"Inferer Health Value\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def symlog_transform(value, linthresh=1e-2, linscale=1):\n","    \"\"\" Approximate symlog transform function.\n","        - linthresh: The threshold where we switch from linear to log scale\n","        - linscale: Controls how steep the linear region should be\n","    \"\"\"\n","    sign = np.sign(value)\n","    abs_value = np.abs(value)\n","    \n","    # Handle zeros explicitly to avoid divide by zero\n","    log_region = np.where(abs_value > 0, np.log10(abs_value), 0)\n","    \n","    # Linear region scaling for small values\n","    linear_region = linscale * abs_value\n","\n","    # Use the log scaling when abs_value > linthresh\n","    return sign * np.where(abs_value > linthresh, log_region, linear_region)\n","\n","\n","# Filter data for raw_forecasts and inferer_losses\n","forecasts = raw_fore_inf_df[raw_fore_inf_df['metric_name'] == 'rawforecasts']\n","losses = raw_fore_inf_df[raw_fore_inf_df['metric_name'] == 'infererlosses']\n","\n","# Group by epoch and address\n","grouped = forecasts.groupby(['epoch', 'address'])['metric_value'].mean().reset_index()\n","grouped = grouped.merge(losses.groupby(['epoch', 'address'])['metric_value'].mean().reset_index(), \n","                        on=['epoch', 'address'], suffixes=('_forecast', '_loss'))\n","\n","# Apply symlog transformation to both the forecast and loss data\n","linthresh = 0.25  # Threshold for linear region\n","grouped['symlog_forecast'] = symlog_transform(grouped['metric_value_forecast'], linthresh=linthresh)\n","grouped['symlog_loss'] = symlog_transform(grouped['metric_value_loss'], linthresh=linthresh)\n","\n","# Create the scatter plot with symlog-transformed data\n","fig = go.Figure()\n","\n","# Add scatter points for forecasts vs losses\n","teal_color = '#21918c'  # Teal color from Viridis\n","\n","fig.add_trace(go.Scatter(\n","    x=grouped['symlog_loss'], \n","    y=grouped['symlog_forecast'], \n","    mode='markers',\n","    marker=dict(size=8, color=teal_color),  # Set all points to teal color\n","    name='',\n","    text=grouped['epoch'],  # Add epoch as text for hover\n","    hovertemplate='<b>Symlog Loss:</b> %{x}<br><b>Symlog Forecast:</b> %{y}<br><b>Epoch:</b> %{text}<extra></extra>'  # Custom hover template\n","))\n","\n","# Calculate min and max values for symlog-transformed data\n","min_value = min(grouped['symlog_loss'].min(), grouped['symlog_forecast'].min())\n","max_value = max(grouped['symlog_loss'].max(), grouped['symlog_forecast'].max())\n","\n","# Expand the range slightly to prevent cutoff\n","padding = (max_value - min_value) * 0.05  # 5% padding\n","min_value_with_padding = min_value - padding\n","max_value_with_padding = max_value + padding\n","\n","# Add y=x reference line (from min to max in symlog space)\n","fig.add_trace(go.Scatter(\n","    x=[min_value_with_padding, max_value_with_padding],\n","    y=[min_value_with_padding, max_value_with_padding],\n","    mode='lines',\n","    name='y=x',\n","    line=dict(color='red', dash='dash')\n","))\n","\n","# Update layout with symlog scales and hoverlabel styling\n","fig.update_layout(\n","    xaxis_title='Observed Losses (Symlog)',\n","    yaxis_title='Forecasted Losses (Symlog)',\n","    title='Forecasters (All data, Symlog Scale)',\n","    title_x=0.5,\n","    height=800,\n","    width=1000,\n","    template=\"plotly_white\",\n","    hovermode=\"closest\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\",\n","        range=[min_value_with_padding, max_value_with_padding],  # Apply padded range for the x-axis\n","        scaleanchor='y',  # Link the scale of the x-axis to the y-axis\n","        constrain='domain',  # Ensure the x-axis is constrained to this range\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\",\n","        range=[min_value_with_padding, max_value_with_padding],  # Apply padded range for the y-axis\n","        scaleratio=1  # Ensure that the ticks on the y-axis are consistent with the x-axis\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",  # Semi-transparent white hover box background\n","        bordercolor=\"rgba(0, 0, 0, 0)\",      # Remove the border\n","        font=dict(\n","            color='black',  # Set font color to black\n","            size=12,\n","            family=\"Arial\"\n","        )\n","    ),\n","    shapes=[\n","        # Vertical line at +linthresh (x-axis)\n","        dict(\n","            type=\"line\",\n","            x0=linthresh,\n","            y0=min_value_with_padding,\n","            x1=linthresh,\n","            y1=max_value_with_padding,\n","            line=dict(color=\"grey\", dash=\"dot\"),\n","            opacity=0.5  # Set opacity for the shape here\n","        ),\n","        # Vertical line at -linthresh (x-axis)\n","        dict(\n","            type=\"line\",\n","            x0=-linthresh,\n","            y0=min_value_with_padding,\n","            x1=-linthresh,\n","            y1=max_value_with_padding,\n","            line=dict(color=\"grey\", dash=\"dot\"),\n","            opacity=0.5  # Set opacity for the shape here\n","        ),\n","        # Horizontal line at +linthresh (y-axis)\n","        dict(\n","            type=\"line\",\n","            x0=min_value_with_padding,\n","            y0=linthresh,\n","            x1=max_value_with_padding,\n","            y1=linthresh,\n","            line=dict(color=\"grey\", dash=\"dot\"),\n","            opacity=0.5\n","        ),\n","        # Horizontal line at -linthresh (y-axis)\n","        dict(\n","            type=\"line\",\n","            x0=min_value_with_padding,\n","            y0=-linthresh,\n","            x1=max_value_with_padding,\n","            y1=-linthresh,\n","            line=dict(color=\"grey\", dash=\"dot\"),\n","            opacity=0.5\n","        )\n","    ],\n","    showlegend=False  # Disable the legend\n",")\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# First, process the weights and forecaster regrets\n","regrets_expanded = []\n","for _, row in forecast_regret_df.iterrows():\n","    # Skip rows where addresses or regrets are None\n","    if row['addresses'] is not None and row['regrets'] is not None:\n","        try:\n","            for addr, regret in zip(row['addresses'], row['regrets']):\n","                regrets_expanded.append({\n","                    'epoch': row['epoch'],\n","                    'addresses': addr,\n","                    'regrets': regret\n","                })\n","        except Exception as e:\n","            print(f\"Error processing row with epoch {row['epoch']}: {e}\")\n","            print(\"Row data:\", row)\n","            continue\n","\n","forecast_regrets_expanded = pd.DataFrame(regrets_expanded)\n","\n","# Get forecaster weights from weights_df\n","def extract_forecaster_weights(row):\n","    # No need for json.loads since the data is already a list\n","    weights = row['forecaster_weights']\n","    return pd.DataFrame(weights)\n","\n","# Create expanded dataframe with forecaster weights\n","forecaster_weights_expanded = pd.DataFrame()\n","for idx, row in weights_df.iterrows():\n","    df_temp = extract_forecaster_weights(row)\n","    df_temp['epoch'] = row['epoch']\n","    df_temp['block_height'] = row['block_height']\n","    forecaster_weights_expanded = pd.concat([forecaster_weights_expanded, df_temp])\n","\n","# Convert weight column to numeric\n","forecaster_weights_expanded['weight'] = pd.to_numeric(forecaster_weights_expanded['weight'])\n","\n","# Merge weights with forecaster regrets\n","forecaster_performance = pd.merge(\n","    forecaster_weights_expanded,\n","    forecast_regrets_expanded,\n","    left_on=['epoch', 'worker'],\n","    right_on=['epoch', 'addresses'],\n","    how='inner'\n",")\n","\n","# Sort by epoch and weight\n","forecaster_performance = forecaster_performance.sort_values(['epoch', 'weight'], ascending=[True, False])\n","\n","# Create scatter plot\n","fig = go.Figure()\n","\n","# Add small constant to weights to avoid log(0)\n","epsilon = 1e-10\n","\n","# Add scatter trace\n","fig.add_trace(\n","    go.Scatter(\n","        x=forecaster_performance['regrets'],\n","        y=np.log10(forecaster_performance['weight'] + epsilon),\n","        mode='markers',\n","        marker=dict(\n","            size=8,\n","            opacity=0.6,\n","            color=forecaster_performance['epoch'],\n","            colorscale='Viridis',\n","            showscale=True,\n","            colorbar=dict(title='Epoch')\n","        ),\n","        hovertemplate=\n","        '<b>Address:</b> %{text}<br>' +\n","        '<b>Regret:</b> %{x:.4f}<br>' +\n","        '<b>Log Weight:</b> %{y:.4f}<br>' +\n","        '<b>Epoch:</b> %{marker.color}<br>' +\n","        '<extra></extra>',\n","        text=forecaster_performance['worker']\n","    )\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    title='Forecaster Regret vs Log Weight',\n","    xaxis_title='Forecaster Regret',\n","    yaxis_title='Log10(Weight + ε)',\n","    template='plotly_white',\n","    height=600,\n","    width=800\n",")\n","\n","# Show plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Reputers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# First, expand the DataFrame\n","rows = []\n","for _, row in listening_df.iterrows():\n","    addresses = row['addresses']\n","    coefficients = row['coefficients']\n","    for addr, coef in zip(addresses, coefficients):\n","        rows.append({\n","            'block_height': row['block_height'],\n","            'epoch': row['epoch'],\n","            'address': addr,\n","            'coefficient': float(coef)\n","        })\n","\n","df_expanded = pd.DataFrame(rows)\n","\n","# Now create the Plotly figure\n","fig = go.Figure()\n","\n","# Add traces for each address\n","for address in df_expanded['address'].unique():\n","    mask = df_expanded['address'] == address\n","    fig.add_trace(\n","        go.Scatter(\n","            x=df_expanded[mask]['epoch'],\n","            y=df_expanded[mask]['coefficient'],\n","            mode='lines+markers',\n","            name=address[:10] + '...',\n","            marker=dict(size=4),\n","        )\n","    )\n","\n","# Update layout\n","fig.update_layout(\n","    title='Listening Coefficients by Epoch',\n","    xaxis_title='Epoch',\n","    yaxis_title='Coefficient Value',\n","    showlegend=True,\n","    legend=dict(\n","        yanchor=\"top\",\n","        y=1,\n","        xanchor=\"left\",\n","        x=1.05\n","    ),\n","    template='plotly_white'\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='rgba(0,0,0,0.2)')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='rgba(0,0,0,0.2)')\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["reputer_rewards = raw_rewards_df[raw_rewards_df['metric_name'] == 'rawreputerreward']\n","# Filter data for reputer rewards and create a copy\n","reputer_rewards = raw_rewards_df[raw_rewards_df['metric_name'] == 'rawreputerreward'].copy()\n","\n","# Divide rewards by 10^18 using loc\n","reputer_rewards.loc[:, 'metric_value'] = reputer_rewards['metric_value'] / 10**18\n","\n","# Create the plot\n","fig = px.scatter(\n","    reputer_rewards,\n","    x='epoch',\n","    y='metric_value',\n","    color='address',\n","    title='Individual Reputer Rewards Over Time',\n","    labels={'metric_value': 'Reward Value', 'epoch': 'Epoch'},\n","    template='plotly_white'\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash='dot',\n","        spikecolor='grey',\n","        dtick=200\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash='dot',\n","        spikecolor='grey'\n","    ),\n","    hovermode='closest',\n","    legend_title_text='Reputer Address',\n","    legend=dict(\n","        yanchor=\"top\",\n","        y=1,\n","        xanchor=\"left\",\n","        x=1.05\n","    )\n",")\n","\n","# Update hover template to show truncated addresses\n","fig.update_traces(\n","    hovertemplate=\"<br>\".join([\n","        \"Epoch: %{x}\",\n","        \"Reward: %{y:.6f}\",\n","        \"Address: %{customdata}\",\n","        \"<extra></extra>\"\n","    ]),\n","    customdata=reputer_rewards['address'].apply(lambda x: x[:10] + '...')\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import plotly.express as px\n","\n","# Filter data for reputer scores\n","reputer_scores = raw_score_df[raw_score_df['metric_name'] == 'rawreputerscore'].copy()\n","\n","# Create the plot\n","fig = px.scatter(\n","    reputer_scores,\n","    x='epoch',\n","    y='metric_value',\n","    color='address',\n","    title='Individual Reputer Scores Over Time',\n","    labels={\n","        'metric_value': 'Score Value', \n","        'epoch': 'Epoch'\n","    },\n","    template='plotly_white'\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash='dot',\n","        spikecolor='grey',\n","        dtick=200\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash='dot',\n","        spikecolor='grey',\n","        type='log'  # Use log scale for y-axis\n","    ),\n","    hovermode='closest',\n","    legend_title_text='Reputer Address',\n","    legend=dict(\n","        yanchor=\"top\",\n","        y=1,\n","        xanchor=\"left\",\n","        x=1.05\n","    )\n",")\n","\n","# Update hover template to show truncated addresses\n","fig.update_traces(\n","    hovertemplate=\"<br>\".join([\n","        \"Epoch: %{x}\",\n","        \"Score: %{y:.6f}\",\n","        \"Address: %{customdata}\",\n","        \"<extra></extra>\"\n","    ]),\n","    customdata=reputer_scores['address'].apply(lambda x: x[:10] + '...')\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# First, let's extract and flatten the stakes data\n","flattened_stakes = []\n","for idx, row in stakes_df.iterrows():\n","    epoch = row['epoch']\n","    stakes = json.loads(row['stakes_array']) if isinstance(row['stakes_array'], str) else row['stakes_array']\n","    for stake_info in stakes:\n","        flattened_stakes.append({\n","            'epoch': epoch,\n","            'stake': float(stake_info['stake']) / 1e18,  # Divide by 10^18\n","            'address': stake_info['address']\n","        })\n","\n","flat_stakes_df = pd.DataFrame(flattened_stakes)\n","\n","# Take log10 of stakes\n","flat_stakes_df['log_stake'] = np.log10(flat_stakes_df['stake'])\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Add a trace for each unique address\n","for address in flat_stakes_df['address'].unique():\n","    address_data = flat_stakes_df[flat_stakes_df['address'] == address]\n","    fig.add_trace(\n","        go.Scatter(\n","            x=address_data['epoch'],\n","            y=address_data['log_stake'],\n","            mode='lines+markers',\n","            name=address[:10] + '...',  # Truncate address for legend\n","            hovertemplate=(\n","                f'<b>Address:</b> {address}<br>' +\n","                '<b>Epoch:</b> %{x}<br>' +\n","                '<b>log₁₀(stake):</b> %{y:.4f}<br>' +\n","                '<b>Stake:</b> %{customdata:.4f}<extra></extra>'\n","            ),\n","            customdata=address_data['stake']  # Original stake values for hover\n","        )\n","    )\n","\n","# Update layout\n","fig.update_layout(\n","    title='Log of Reputer Stakes Over Time',\n","    xaxis_title='Epoch',\n","    yaxis_title='log₁₀(Stake)',\n","    height=600,\n","    width=1000,\n","    template='plotly_white',\n","    hovermode='x unified',\n","    showlegend=True,\n","    legend=dict(\n","        yanchor=\"top\",\n","        y=0.99,\n","        xanchor=\"left\",\n","        x=1.02\n","    ),\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash='dot',\n","        spikecolor='grey'\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash='dot',\n","        spikecolor='grey'\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font=dict(\n","            size=12,\n","            family=\"Arial\"\n","        )\n","    )\n",")\n","\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","# Ensure all epochs are included\n","all_epochs = pd.DataFrame({'epoch': range(reputer_payload_df['epoch'].min(), reputer_payload_df['epoch'].max() + 1)})\n","\n","# Merge the epochs with the payload data, filling missing epochs with payload_count = 0\n","reputer_payload_df_full = pd.merge(all_epochs, reputer_payload_df[['epoch', 'payload_count']], on='epoch', how='left').fillna({'payload_count': 0})\n","\n","# Create plot\n","fig = go.Figure()\n","\n","# Add number of payloads trace\n","fig.add_trace(\n","    go.Scatter(\n","        x=reputer_payload_df_full['epoch'],\n","        y=reputer_payload_df_full['payload_count'],\n","        mode='lines+markers',\n","        name='Number of Payloads',\n","        marker=dict(size=6),\n","        line=dict(width=2),\n","        hovertemplate='<b>Epoch:</b> %{x}<br><b>Number of Payloads:</b> %{y}<extra></extra>'\n","    )\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    title='Number of Payloads Over Time',\n","    xaxis_title='Epoch',\n","    yaxis_title='Number of Payloads',\n","    height=600,\n","    width=1000,\n","    template='plotly_white',\n","    hovermode='x unified',\n","    showlegend=True,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        rangemode='nonnegative'  # Ensures y-axis starts at 0 or above\n","    )\n",")\n","\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenomics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["current_token_details"]},{"cell_type":"code","execution_count":984,"metadata":{},"outputs":[],"source":["# actual_current_block_emission = current_token_details['previous_block_emission'].values[0]\n","# last_height_update = current_token_details['last_height_update'].values[0]\n","# next_height_update = current_token_details['next_height_update'].values[0]\n","# current_height = current_token_details['block_height'].values[0]\n","# ecosystem_remaining = current_token_details['ecosystem_mint_supply_remaining'].values[0]\n","# blocks_per_month = current_token_details['blocks_per_month'].values[0]\n","\n","\n","# target_emission_rate_per_unit_staked_token = current_token_details['target_emission_rate_per_unit_staked_token'].values[0]\n","# network_staked = current_token_details['network_staked'].values[0]\n","# emission_per_unit_staked_token = current_token_details['emission_per_unit_staked_token'].values[0]\n","\n","# circulating_supply = current_token_details['circulating_supply'].values[0]\n","# total_locked = current_token_details['total_locked'].values[0]\n","# max_supply = current_token_details['max_supply'].values[0]\n","\n","# months_remaining = ecosystem_remaining /(actual_current_block_emission*blocks_per_month)\n","# years_remaining= months_remaining /12\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create new interactive plot\n","fig = go.Figure()\n","\n","# Add emission line\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=new_supply_df['previous_emission'],\n","        mode='lines+markers',\n","        name='Actual Emission',\n","        line=dict(color='blue', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","\n","# Update layout\n","fig.update_layout(\n","    title='Actual Emission per Block Values',\n","    xaxis_title='Block Height',\n","    yaxis_title='Actual Emission',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat='.2e',\n","        showexponent='all',\n","        exponentformat='e',\n","        showgrid=True\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Sortition"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filter the DataFrame for the reputer_score metric\n","reputer_score_df = df[df['metric_name'] == 'reputerscore']\n","reputer_score_df = reputer_score_df.sort_values(by='epoch')\n","\n","\n","# Calculate EMA with alpha = 0.1\n","alpha = 0.1\n","ema_values = reputer_score_df['metric_value'].ewm(alpha=alpha).mean()\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define Viridis color for the Reputer Health line\n","reputer_color = '#21918c'  # Teal from Viridis\n","\n","# Plot Reputer Health line\n","fig.add_trace(go.Scatter(\n","    x=reputer_score_df['epoch'],\n","    y=reputer_score_df['metric_value'],\n","    mode='lines+markers',\n","    name='Reputer Health',\n","    line=dict(color=reputer_color),\n","    marker=dict(color=reputer_color),\n","    hovertemplate='Reputer Score: %{y:.2f}<extra></extra>'\n","))\n","\n","# Add EMA line with red color and Greek letter alpha in the name\n","fig.add_trace(go.Scatter(\n","    x=reputer_score_df['epoch'],\n","    y=ema_values,\n","    mode='lines',\n","    name='EMA',  # HTML code for alpha\n","    line=dict(color='red', dash='solid', width=2),\n","    hovertemplate='EMA: %{y:.2f}<extra></extra>'\n","))\n","\n","# Update the layout with Viridis style settings\n","fig.update_layout(\n","    title=f\"Reputer Score Metric for Topic {reputer_score_df['topic_id'].iloc[0]}\",\n","    xaxis_title=\"Epoch\",\n","    yaxis_title=\"Metric\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filter the DataFrame for the forecast_health metric\n","sortition_score_df = df[df['metric_name'] == 'sortitionscore']\n","sortition_score_df = sortition_score_df.sort_values(by='epoch')\n","\n","# Calculate EMA with alpha = 0.1\n","alpha = 0.1\n","ema_values = sortition_score_df['metric_value'].ewm(alpha=alpha).mean()\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define Viridis color for the original line\n","score_color = '#440154'  # Dark purple from Viridis\n","\n","# Add original Sortition Score data points\n","fig.add_trace(go.Scatter(\n","    x=sortition_score_df['epoch'],\n","    y=sortition_score_df['metric_value'],\n","    mode='lines+markers',\n","    name='Sortition Score',\n","    line=dict(color=score_color),\n","    marker=dict(color=score_color),\n","    hovertemplate='Sortition Score: %{y:.3f}<extra></extra>'\n","))\n","\n","# Add EMA line (red) on top of the sortition score values\n","fig.add_trace(go.Scatter(\n","    x=sortition_score_df['epoch'],\n","    y=ema_values,\n","    mode='lines',\n","    name='EMA',\n","    line=dict(color='red', dash='solid', width=2),\n","    hovertemplate='EMA: %{y:.3f}<extra></extra>'\n","))\n","\n","# Update the layout with Viridis style settings\n","fig.update_layout(\n","    title=f\"Sortition Score Metric for Topic {sortition_score_df['topic_id'].iloc[0]}\",\n","    xaxis_title=\"Epoch\",\n","    yaxis_title=\"Metric\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Cycle time estimate"]},{"cell_type":"markdown","metadata":{},"source":["- We plot\n","    - $$\\frac{\\text{avg}(Q_{i}^{add}) - \\text{avg}(Q_{i}^{rem})}{N_i}$$\n","    - where $$Q_i$$ is the ema score and $$N_i$$ is the number of replacements in the active set at epoch $$i$$\n","- A **large/positive** value is **healthy** and corresponds to increasing the quality of the active set😁✅\n","- A **small/negative** value is **unhealthy** and corresponds to decreasing the quality of the active set😢😷"]},{"cell_type":"markdown","metadata":{},"source":["## Average quality difference"]},{"cell_type":"markdown","metadata":{},"source":["# Merit-based sortition health"]},{"cell_type":"markdown","metadata":{},"source":["The below is only for inferers! (we should add a filter for worker type..)"]},{"cell_type":"markdown","metadata":{},"source":["## Reputer scores metric (WIP)"]},{"cell_type":"markdown","metadata":{},"source":["- We plot\n","    - $$\\log\\left(\\frac{\\text{mean}(\\text{scores})}{\\text{std}(\\text{scores})^2+\\epsilon}\\right)$$\n","    - with $$\\epsilon =10^{-6}$$\n","- A **large/positive** value is **healthy** and corresponds to the reputer's having large and similar scores 😁✅\n","- A **small/negative** value is **unhealthy** and corresponds to the reputer's having small and varying scores 😢😷"]},{"cell_type":"markdown","metadata":{},"source":["- We plot\n","    - $$\\frac{P_i}{N_i+1}$$\n","    - where $$P_i$$ is the number of participants and $$N_i$$ is the number of replacements in the active set at epoch $$i$$\n","- This metric estimates the number of epochs it will take to cycle through all participants on topic {{topic_id}}\n","    - A **small** value is **healthy** means we cycle through the particpants quickly 😁✅\n","    - A **large** value is **unhealthy** and means it will take several epochs to cycle through all participants 😢😷\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Filter the DataFrame for the sortition_time metric and remove rows where metric_value is 0 or 1\n","sortition_time_df = df[(df['metric_name'] == 'sortitiontime') & (df['metric_value'] != 0) & (df['metric_value'] != 1)].copy()\n","sortition_time_df = sortition_time_df.sort_values(by='epoch')\n","\n","# Apply log transformation to metric_value using .loc to avoid the warning\n","sortition_time_df.loc[:, 'log_metric_value'] = np.log10(sortition_time_df['metric_value'])\n","\n","# Calculate EMA on the log-transformed values with alpha = 0.1\n","alpha = 0.1\n","ema_values = sortition_time_df['log_metric_value'].ewm(alpha=alpha).mean()\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define Viridis color for the line\n","sortition_color = '#3b528b'  # Mid blue from Viridis\n","\n","# Add original log-transformed data points\n","fig.add_trace(go.Scatter(\n","    x=sortition_time_df['epoch'],\n","    y=sortition_time_df['log_metric_value'],  # Use log-transformed values\n","    mode='lines+markers',\n","    name='Sortition Time (Log)',\n","    line=dict(color=sortition_color),\n","    marker=dict(color=sortition_color),\n","    hovertemplate='Log Sortition Time: %{y:.2f}<extra></extra>'  # Hover shows log-transformed values\n","))\n","\n","# Add EMA line (red) on top of the log-transformed values\n","fig.add_trace(go.Scatter(\n","    x=sortition_time_df['epoch'],\n","    y=ema_values,\n","    mode='lines',\n","    name='EMA (Log)',\n","    line=dict(color='red', dash='solid', width=2),\n","    hovertemplate='EMA (Log): %{y:.2f}<extra></extra>'\n","))\n","\n","# Update the layout with Viridis style settings and linear scale for y-axis\n","fig.update_layout(\n","    title=f\"Log Sortition Time Metric for Topic {sortition_time_df['topic_id'].iloc[0]}\",\n","    xaxis_title=\"Epoch\",\n","    yaxis_title=\"Log(Metric)\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Inferer lifetime estimate"]},{"cell_type":"markdown","metadata":{},"source":["- We plot\n","    - $$\\frac{A_i}{N_i+\\epsilon}$$\n","    - where $$A_i$$ is the number of active inferrers, $$N_i$$ is the number of replacements in the active set at epoch $$i$$, and $$\\epsilon=10^{-6}$$\n","- This metric estimates how many epochs an inferrer typically stays active in the active set on topic {{topic_id}}\n","    - A **very small** value (close to 1) is **unhealthy** and indicates excessive churn in the active set 😢\n","    - A **moderate** value is **healthy** as it indicates appropriate turnover in the active set 😁✅\n","    - A **very large** value is **unhealthy** as it suggests the active set is stagnant with insufficient rotation of participants 😷"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filter the DataFrame for the lifetime metric and remove rows where metric_value is 0 or 1\n","life_time_df = df[(df['metric_name'] == 'lifetime')].copy()\n","life_time_df = life_time_df.sort_values(by='epoch')\n","\n","# Apply log transformation to metric_value using .loc to avoid the warning\n","life_time_df.loc[:, 'log_metric_value'] = np.log10(life_time_df['metric_value'])\n","\n","# Calculate EMA on the log-transformed values with alpha = 0.1\n","alpha = 0.1\n","ema_values = life_time_df['log_metric_value'].ewm(alpha=alpha).mean()\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define Viridis color for the line\n","lifetime_color = '#21918c'  # Mid blue from Viridis\n","\n","# Add original log-transformed data points\n","fig.add_trace(go.Scatter(\n","    x=life_time_df['epoch'],\n","    y=life_time_df['log_metric_value'],  # Use log-transformed values\n","    mode='lines+markers',\n","    name='Lifetime (Log)',  # Updated name\n","    line=dict(color=lifetime_color),\n","    marker=dict(color=lifetime_color),\n","    hovertemplate='Log Lifetime: %{y:.2f}<extra></extra>'  # Updated hover text\n","))\n","\n","# Add EMA line (red) on top of the log-transformed values\n","fig.add_trace(go.Scatter(\n","    x=life_time_df['epoch'],\n","    y=ema_values,\n","    mode='lines',\n","    name='EMA (Log)',\n","    line=dict(color='red', dash='solid', width=2),\n","    hovertemplate='EMA (Log): %{y:.2f}<extra></extra>'\n","))\n","\n","# Update the layout with Viridis style settings and linear scale for y-axis\n","fig.update_layout(\n","    title=f\"Log Lifetime Metric for Topic {life_time_df['topic_id'].iloc[0]}\",  # Updated title\n","    xaxis_title=\"Epoch\",\n","    yaxis_title=\"Log(Lifetime Metric)\",  # Updated y-axis label\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["Number of active inferers, should be 32!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Sort the DataFrame by epoch\n","num_active_df = num_active_df.sort_values(by='epoch')\n","\n","# Calculate EMA with alpha = 0.1\n","alpha = 0.1\n","ema_values = num_active_df['inferrerlosses_count'].ewm(alpha=alpha).mean()\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define Viridis color for the line\n","count_color = '#3b528b'  # Mid blue from Viridis\n","\n","# Add horizontal line at y=32\n","fig.add_trace(go.Scatter(\n","    x=[num_active_df['epoch'].min(), num_active_df['epoch'].max()],\n","    y=[32, 32],\n","    mode='lines',\n","    name='Expected',\n","    line=dict(color='gray', dash='dot', width=1),\n","    hovertemplate='Expected: 32<extra></extra>'\n","))\n","\n","# Add original data points\n","fig.add_trace(go.Scatter(\n","    x=num_active_df['epoch'],\n","    y=num_active_df['inferrerlosses_count'],\n","    mode='lines+markers',\n","    name='Active Inferers',\n","    line=dict(color=count_color),\n","    marker=dict(color=count_color),\n","    hovertemplate='Active Inferers: %{y}<extra></extra>'\n","))\n","\n","# Add EMA line\n","fig.add_trace(go.Scatter(\n","    x=num_active_df['epoch'],\n","    y=ema_values,\n","    mode='lines',\n","    name='EMA',\n","    line=dict(color='red', dash='solid', width=2),\n","    hovertemplate='EMA: %{y:.2f}<extra></extra>'\n","))\n","\n","# Rest of the layout code remains the same\n","fig.update_layout(\n","    title=f\"Number of Active Inferers for Topic {num_active_df['topic_id'].iloc[0]}\",\n","    xaxis_title=\"Epoch\",\n","    yaxis_title=\"Number of Active Inferers\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example: Plot original metrics with Reputer first, then Inferer, then Forecaster\n","# Define colors for the scatter points\n","inferer_color = '#3b528b'  # Mid blue from Viridis (for inferers)\n","forecaster_color = '#fde725'  # Bright yellow from Viridis (for forecasters)\n","\n","dataframe_metrics = raw_rewards_df  # Your DataFrame here\n","# Change the order of the metrics and their labels\n","original_metrics = ['rawreputerreward', 'rawinfererreward', 'rawforecasterreward']\n","renamed_metrics = ['Reputer rewards', 'Inferer rewards', 'Forecaster rewards']\n","dataframe_metrics['metric_value'] = dataframe_metrics['metric_value'] / 10**18\n","# Divide all rewards by 10^18\n","# dataframe_metrics['metric_value'] = dataframe_metrics['metric_value']\n","\n","# Colors from the previous cell (Reputer first, Inferer second, Forecaster third)\n","colors = [reputer_color, inferer_color, forecaster_color]\n","\n","# Create subplots for the bottom row (Cumulative rewards)\n","num_metrics = len(original_metrics)\n","fig = make_subplots(rows=1, cols=num_metrics, \n","                    subplot_titles=[f\"Cumulative {renamed_metrics[i]}\" for i in range(num_metrics)],\n","                    horizontal_spacing=0.05,  # Reduce horizontal spacing\n","                    shared_yaxes=True)  # Keep shared y-axis to maintain consistent ticks\n","\n","for i, metric_name in enumerate(original_metrics):\n","    metric_data = dataframe_metrics[dataframe_metrics['metric_name'] == metric_name]\n","    \n","    # Check if there is data for this metric\n","    if metric_data.empty:\n","        print(f\"No data found for {metric_name}, skipping.\")\n","        continue\n","    \n","    # Plot cumulative rewards (Bottom row)\n","    sum_per_epoch = metric_data.groupby('epoch')['metric_value'].sum().reset_index()\n","    cumulative_data = sum_per_epoch['metric_value'].cumsum()\n","    \n","    # Manually log-transform the cumulative data\n","    cumulative_data_log = np.log10(cumulative_data.replace(0, np.nan))  # Replace 0 with NaN to avoid log issues\n","    \n","    fig.add_trace(go.Scatter(\n","        x=sum_per_epoch['epoch'], \n","        y=cumulative_data_log,  # Use log-transformed cumulative data\n","        mode='lines+markers', \n","        line=dict(color=colors[i], width=2),  # Use the previously defined colors and increased line width\n","        marker=dict(color=colors[i]),\n","        name=f\"Cumulative {renamed_metrics[i]}\",\n","        hovertemplate='%{y:.2f}<extra></extra>'  # Use Plotly's hover template syntax\n","    ), row=1, col=i+1)\n","\n","# Update layout with your preferred style\n","fig.update_layout(\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    font=dict(size=12),  # Set consistent font size for axis labels and ticks\n","    showlegend=False,  # Turn off the legend\n","    margin=dict(l=70, r=30, t=30, b=30),  # Increase left margin to allow y-axis label\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\"\n","    )\n",")\n","\n","# Update x-axes to ensure the same ticks\n","fig.update_xaxes(\n","    title_text=\"Epoch\", \n","    title_font=dict(size=12), \n","    tickfont=dict(size=12),\n","    showspikes=True,\n","    spikemode='across',\n","    spikesnap='cursor',\n","    spikethickness=1,\n","    spikedash=\"dot\",\n","    spikecolor=\"grey\",\n","    dtick=50,  # Set tick interval to every 200 epochs\n","    matches=\"x\"  # Ensure all plots share the same x-axis\n",")\n","\n","# Ensure all bottom plots share the same y-axis ticks but only show labels for the first column\n","for i in range(1, num_metrics + 1):\n","    fig.update_yaxes(\n","        title_text=\"Log(Cumulative Rewards)\" if i == 1 else None,  # Add y-axis label only to the first column\n","        type=\"linear\",  # Use linear scale since data is manually log-transformed\n","        title_font=dict(size=12), \n","        tickfont=dict(size=12),\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\",\n","        showticklabels=True,  # Ensure ticks are shown for all subplots\n","        row=1, col=i\n","    )\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Aggregate and calculate average reward per worker type per epoch\n","average_rewards = dataframe_metrics.groupby(['epoch', 'metric_name'])['metric_value'].mean().reset_index()\n","\n","# Create subplots for the average rewards\n","fig = make_subplots(rows=1, cols=num_metrics, \n","                    subplot_titles=[f\"Average {renamed_metrics[i]} per Worker\" for i in range(num_metrics)],\n","                    horizontal_spacing=0.05,  # Reduce horizontal spacing\n","                    shared_yaxes=True)  # Keep shared y-axis to maintain consistent ticks\n","\n","for i, metric_name in enumerate(original_metrics):\n","    metric_data = average_rewards[average_rewards['metric_name'] == metric_name]\n","    \n","    # Check if there is data for this metric\n","    if metric_data.empty:\n","        print(f\"No data found for {metric_name}, skipping.\")\n","        continue\n","    \n","    # Plot average rewards\n","    fig.add_trace(go.Scatter(\n","        x=metric_data['epoch'], \n","        y=metric_data['metric_value'],  # Average rewards\n","        mode='lines+markers', \n","        line=dict(color=colors[i], width=2),  # Use the previously defined colors and increased line width\n","        marker=dict(color=colors[i]),\n","        name=f\"Average {renamed_metrics[i]} per Worker\",\n","        hovertemplate='%{y:.2f}<extra></extra>'  # Use Plotly's hover template syntax\n","    ), row=1, col=i+1)\n","\n","# Update layout with your preferred style\n","fig.update_layout(\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    font=dict(size=12),  # Set consistent font size for axis labels and ticks\n","    showlegend=False,  # Turn off the legend\n","    margin=dict(l=70, r=30, t=30, b=30),  # Increase left margin to allow y-axis label\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\"\n","    )\n",")\n","\n","# Update x-axes to ensure the same ticks\n","fig.update_xaxes(\n","    title_text=\"Epoch\", \n","    title_font=dict(size=12), \n","    tickfont=dict(size=12),\n","    showspikes=True,\n","    spikemode='across',\n","    spikesnap='cursor',\n","    spikethickness=1,\n","    spikedash=\"dot\",\n","    spikecolor=\"grey\",\n","    dtick=50,  # Set tick interval to every 200 epochs\n","    matches=\"x\"  # Ensure all plots share the same x-axis\n",")\n","\n","# Ensure all bottom plots share the same y-axis ticks but only show labels for the first column\n","for i in range(1, num_metrics + 1):\n","    fig.update_yaxes(\n","        title_text=\"Average Rewards\" if i == 1 else None,  # Add y-axis label only to the first column\n","        type=\"linear\",  # Use linear scale for average rewards\n","        title_font=dict(size=12), \n","        tickfont=dict(size=12),\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\",\n","        showticklabels=True,  # Ensure ticks are shown for all subplots\n","        row=1, col=i\n","    )\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Aggregate and calculate average reward per worker type per epoch\n","average_rewards = dataframe_metrics.groupby(['epoch', 'metric_name'])['metric_value'].mean().reset_index()\n","\n","# Create a single plot for all metrics\n","fig = go.Figure()\n","\n","for i, metric_name in enumerate(original_metrics):\n","    metric_data = average_rewards[average_rewards['metric_name'] == metric_name]\n","    \n","    # Check if there is data for this metric\n","    if metric_data.empty:\n","        print(f\"No data found for {metric_name}, skipping.\")\n","        continue\n","    metric_data['metric_value'] = np.log10(metric_data['metric_value'])\n","    # Add a line for each metric\n","    fig.add_trace(go.Scatter(\n","        x=metric_data['epoch'], \n","        y=metric_data['metric_value'],  # Average rewards\n","        mode='lines+markers', \n","        line=dict(color=colors[i], width=2),  # Use the previously defined colors and increased line width\n","        marker=dict(color=colors[i]),\n","        name=f\"Average {renamed_metrics[i]} per Worker\",\n","        hovertemplate='%{y:.2f}<extra></extra>'  # Use Plotly's hover template syntax\n","    ))\n","\n","# Update layout with your preferred style\n","fig.update_layout(\n","    title=\"Average Rewards by Worker Type\",\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    font=dict(size=12),  # Set consistent font size for axis labels and ticks\n","    showlegend=True,  # Enable the legend to distinguish metrics\n","    margin=dict(l=70, r=30, t=30, b=30),  # Increase left margin to allow y-axis label\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\"\n","    ),\n","    xaxis=dict(\n","        title=\"Epoch\",\n","        title_font=dict(size=12),\n","        tickfont=dict(size=12),\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\",\n","        dtick=50  # Set tick interval to every 200 epochs\n","    ),\n","    yaxis=dict(\n","        title=\"Average Rewards\",\n","        title_font=dict(size=12),\n","        tickfont=dict(size=12),\n","        type=\"linear\",  # Use linear scale for average rewards\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    )\n",")\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Aggregate and calculate the count of workers per metric type per epoch\n","worker_counts = dataframe_metrics.groupby(['epoch', 'metric_name'])['address'].nunique().reset_index()\n","\n","# Create a single plot for worker counts\n","fig_counts = go.Figure()\n","\n","for i, metric_name in enumerate(original_metrics):\n","    metric_data = worker_counts[worker_counts['metric_name'] == metric_name]\n","    \n","    # Check if there is data for this metric\n","    if metric_data.empty:\n","        print(f\"No data found for {metric_name}, skipping.\")\n","        continue\n","    \n","    # Add a line for each metric\n","    fig_counts.add_trace(go.Scatter(\n","        x=metric_data['epoch'], \n","        y=metric_data['address'],  # Count of unique workers\n","        mode='lines+markers', \n","        line=dict(color=colors[i], width=2),  # Use the previously defined colors and increased line width\n","        marker=dict(color=colors[i]),\n","        name=f\"Number of {renamed_metrics[i]}\",\n","        hovertemplate='%{y}<extra></extra>'  # Use Plotly's hover template syntax\n","    ))\n","\n","# Update layout with your preferred style\n","fig_counts.update_layout(\n","    title=\"Number of Workers per Type by Epoch\",\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    font=dict(size=12),  # Set consistent font size for axis labels and ticks\n","    showlegend=True,  # Enable the legend to distinguish metrics\n","    margin=dict(l=70, r=30, t=30, b=30),  # Increase left margin to allow y-axis label\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\"\n","    ),\n","    xaxis=dict(\n","        title=\"Epoch\",\n","        title_font=dict(size=12),\n","        tickfont=dict(size=12),\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\",\n","        dtick=50  # Set tick interval to every 200 epochs\n","    ),\n","    yaxis=dict(\n","        title=\"Number of Workers\",\n","        title_font=dict(size=12),\n","        tickfont=dict(size=12),\n","        type=\"linear\",  # Use linear scale for worker counts\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    )\n",")\n","\n","# Show the plot\n","fig_counts.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define blue color for the line\n","line_color = '#1f77b4'  # Standard plotly blue\n","\n","# Add the main line\n","fig.add_trace(go.Scatter(\n","    x=time_df['block_time'],\n","    y=time_df['epoch'],\n","    mode='lines+markers',\n","    name='Epoch Progress',\n","    line=dict(color=line_color),\n","    marker=dict(color=line_color),\n","    hovertemplate='Epoch: %{y}<br>Time: %{x}<extra></extra>'\n","))\n","\n","# Update the layout with matching style settings\n","fig.update_layout(\n","    title=\"Epoch Progress Over Time\",\n","    xaxis_title=\"Time\",\n","    yaxis_title=\"Epoch\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the plot\n","fig = go.Figure()\n","\n","# Define Viridis color for the line\n","line_color = '#440154'  # Bright purple from Viridis\n","\n","# Add the main line\n","fig.add_trace(go.Scatter(\n","    x=time_df['block_time'],\n","    y=time_df['block_height'],  # Changed from epoch to block_height\n","    mode='lines+markers',\n","    name='Block Height Progress',  # Updated name\n","    line=dict(color=line_color),\n","    marker=dict(color=line_color),\n","    hovertemplate='Block Height: %{y}<br>Time: %{x}<extra></extra>'  # Updated hover template\n","))\n","\n","# Update the layout with matching style settings\n","fig.update_layout(\n","    title=\"Block Height Progress Over Time\",  # Updated title\n","    xaxis_title=\"Time\",\n","    yaxis_title=\"Block Height\",  # Updated y-axis label\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert block_time to timestamps if not already\n","time_df['block_time'] = pd.to_datetime(time_df['block_time'])\n","\n","# Calculate time difference between consecutive blocks in seconds\n","time_df['time_diff'] = time_df['block_time'].diff().dt.total_seconds()\n","\n","# Calculate blocks difference (should be constant if consecutive blocks)\n","time_df['block_diff'] = time_df['block_height'].diff()\n","\n","# Calculate seconds per block\n","time_df['seconds_per_block'] = time_df['time_diff'] / time_df['block_diff']\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define Viridis color for the line\n","line_color = '#440154'  # Bright purple from Viridis\n","\n","# Add the main line\n","fig.add_trace(go.Scatter(\n","    x=time_df['block_time'],\n","    y=np.log10(time_df['seconds_per_block']),  # Take log10 of the values\n","    mode='lines+markers',\n","    name='Seconds per Block (log10)',\n","    line=dict(color=line_color),\n","    marker=dict(color=line_color),\n","    hovertemplate='Seconds per Block: %{text:.2f}<br>Log10: %{y:.2f}<br>Time: %{x}<extra></extra>',\n","    text=time_df['seconds_per_block']  # Original values for hover text\n","))\n","\n","# Calculate and add mean line\n","mean_seconds = time_df['seconds_per_block'].mean()\n","fig.add_trace(go.Scatter(\n","    x=time_df['block_time'],\n","    y=[np.log10(mean_seconds)] * len(time_df),  # Take log10 of mean\n","    mode='lines',\n","    name=f'Mean ({mean_seconds:.2f}s)',\n","    line=dict(color='red', dash='dash'),\n","    hovertemplate='Mean: ' + f'{mean_seconds:.2f}s<br>Log10: %{{y:.2f}}<extra></extra>'  # Fixed syntax\n","))\n","\n","# Update the layout with matching style settings\n","fig.update_layout(\n","    title=\"Log of Seconds per Block Over Time\",\n","    xaxis_title=\"Time\",\n","    yaxis_title=\"Log(Seconds per Block)\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Aggregate rewards by worker (address) and epoch\n","worker_rewards = dataframe_metrics.groupby(['epoch', 'address', 'metric_name'])['metric_value'].mean().reset_index()\n","\n","# Create subplots for the worker-specific rewards\n","fig = make_subplots(rows=1, cols=num_metrics, \n","                    subplot_titles=[f\"Worker-Specific {renamed_metrics[i]}\" for i in range(num_metrics)],\n","                    horizontal_spacing=0.05,  # Reduce horizontal spacing\n","                    shared_yaxes=True)  # Keep shared y-axis to maintain consistent ticks\n","\n","for i, metric_name in enumerate(original_metrics):\n","    metric_data = worker_rewards[worker_rewards['metric_name'] == metric_name]\n","    \n","    # Check if there is data for this metric\n","    if metric_data.empty:\n","        print(f\"No data found for {metric_name}, skipping.\")\n","        continue\n","\n","    # Loop through each worker and plot their rewards\n","    for worker in metric_data['address'].unique():\n","        worker_data = metric_data[metric_data['address'] == worker]\n","        fig.add_trace(go.Scatter(\n","            x=worker_data['epoch'], \n","            y=worker_data['metric_value'], \n","            mode='lines', \n","            line=dict(width=1),  # Use thinner lines for multiple workers\n","            name=f\"{renamed_metrics[i]} - {worker}\",\n","            legendgroup=f\"{metric_name}\",  # Group lines for each metric\n","            showlegend=False if i > 0 else True,  # Only show legend for the first metric\n","            hovertemplate='%{y:.2f}<extra></extra>'\n","        ), row=1, col=i+1)\n","\n","# Update layout with your preferred style\n","fig.update_layout(\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    font=dict(size=12),  # Set consistent font size for axis labels and ticks\n","    showlegend=False,  # Turn off the legend\n","    margin=dict(l=70, r=30, t=30, b=30),  # Increase left margin to allow y-axis label\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\"\n","    )\n",")\n","\n","# Update x-axes to ensure the same ticks\n","fig.update_xaxes(\n","    title_text=\"Epoch\", \n","    title_font=dict(size=12), \n","    tickfont=dict(size=12),\n","    showspikes=True,\n","    spikemode='across',\n","    spikesnap='cursor',\n","    spikethickness=1,\n","    spikedash=\"dot\",\n","    spikecolor=\"grey\",\n","    dtick=50,  # Set tick interval to every 200 epochs\n","    matches=\"x\"  # Ensure all plots share the same x-axis\n",")\n","\n","# Ensure all bottom plots share the same y-axis ticks but only show labels for the first column\n","for i in range(1, num_metrics + 1):\n","    fig.update_yaxes(\n","        title_text=\"Worker-Specific Rewards\" if i == 1 else None,  # Add y-axis label only to the first column\n","        type=\"linear\",  # Use linear scale for worker rewards\n","        title_font=dict(size=12), \n","        tickfont=dict(size=12),\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\",\n","        showticklabels=True,  # Ensure ticks are shown for all subplots\n","        row=1, col=i\n","    )\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import plotly.graph_objects as go\n","\n","# Assume the DataFrame raw_rewards_df is already defined\n","dataframe_metrics = raw_rewards_df.sort_values(by='epoch')\n","\n","# Divide all rewards by 10^18\n","dataframe_metrics['metric_value'] = dataframe_metrics['metric_value'] / 10**18\n","\n","# First sum rewards by worker type and epoch\n","summed_rewards = dataframe_metrics.groupby(['epoch', 'metric_name'])['metric_value'].sum().reset_index()\n","\n","# Calculate total rewards per epoch\n","total_rewards_per_epoch = summed_rewards.groupby('epoch')['metric_value'].sum().reset_index()\n","total_rewards_per_epoch.rename(columns={'metric_value': 'total_rewards'}, inplace=True)\n","\n","# Merge total rewards with the summed data\n","summed_rewards = summed_rewards.merge(total_rewards_per_epoch, on='epoch')\n","\n","# Calculate the fraction of rewards for each worker type\n","summed_rewards['fraction'] = summed_rewards['metric_value'] / summed_rewards['total_rewards']\n","\n","# Define colors for Reputer, Inferer, and Forecaster\n","colors = {\n","    'rawreputerreward': '#21918c',  # Teal\n","    'rawinfererreward': '#3b528b',  # Mid blue\n","    'rawforecasterreward': '#fde725'  # Bright yellow\n","}\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Plot fractions for each worker type\n","for metric_name, color in colors.items():\n","    metric_data = summed_rewards[summed_rewards['metric_name'] == metric_name]\n","    fig.add_trace(go.Scatter(\n","        x=metric_data['epoch'],\n","        y=metric_data['fraction'],\n","        mode='lines+markers',\n","        line=dict(color=color, width=2),\n","        marker=dict(color=color, size=4),\n","        name=metric_name.replace('raw', '').replace('reward', ''),\n","        hovertemplate='Epoch: %{x}<br>Fraction: %{y:.3f}<extra></extra>'\n","    ))\n","\n","# Add a horizontal line at y=1/3\n","fig.add_hline(y=1/3, line_dash=\"dash\", line_color=\"gray\", \n","              annotation_text=\"Equal Split (1/3)\", \n","              annotation_position=\"right\")\n","\n","# Update layout\n","fig.update_layout(\n","    title='Fraction of Rewards per Worker Type',\n","    xaxis_title='Epoch',\n","    yaxis_title='Fraction of Total Rewards',\n","    template='plotly_white',\n","    hovermode='x unified',\n","    spikedistance=-1,\n","    showlegend=True,\n","    legend=dict(\n","        yanchor='top',\n","        y=1,\n","        xanchor='left',\n","        x=1.05\n","    ),\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash='dot',\n","        spikecolor='grey',\n","        dtick=50\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash='dot',\n","        spikecolor='grey',\n","        range=[0, 1]  # Set y-axis range from 0 to 1\n","    ),\n","    hoverlabel=dict(\n","        bgcolor='rgba(255, 255, 255, 0.7)',\n","        bordercolor='rgba(0, 0, 0, 0)',\n","        font_size=12,\n","        font_family='Arial'\n","    )\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import numpy as np\n","# import pandas as pd\n","# import plotly.graph_objects as go\n","# from plotly.subplots import make_subplots\n","\n","# Filter data for raw scores\n","# Filter and sort by 'epoch' for reputer scores\n","reputer_scores = raw_score_df[raw_score_df['metric_name'] == 'rawreputerscore'].copy()\n","reputer_scores = reputer_scores.sort_values(by='epoch')\n","\n","# Filter and sort by 'epoch' for inferer scores\n","inferer_scores = raw_score_df[raw_score_df['metric_name'] == 'rawinfererscore'].copy()\n","inferer_scores = inferer_scores.sort_values(by='epoch')\n","\n","# Filter and sort by 'epoch' for forecaster scores\n","forecaster_scores = raw_score_df[raw_score_df['metric_name'] == 'rawforecasterscore'].copy()\n","forecaster_scores = forecaster_scores.sort_values(by='epoch')\n","\n","\n","# Calculate average of scores for each category\n","reputer_avg = reputer_scores.groupby('epoch')['metric_value'].mean().reset_index()\n","inferer_avg = inferer_scores.groupby('epoch')['metric_value'].mean().reset_index()\n","forecaster_avg = forecaster_scores.groupby('epoch')['metric_value'].mean().reset_index()\n","\n","# Manually log-transform the reputer data\n","reputer_avg['log_metric_value'] = np.log10(reputer_avg['metric_value'].replace(0, np.nan))  # Replace 0 with NaN to avoid log issues\n","\n","# Calculate EMA for each category\n","alpha = 0.1  # Smoothing factor for EMA\n","reputer_avg['ema'] = reputer_avg['log_metric_value'].ewm(alpha=alpha).mean()\n","inferer_avg['ema'] = inferer_avg['metric_value'].ewm(alpha=alpha).mean()\n","forecaster_avg['ema'] = forecaster_avg['metric_value'].ewm(alpha=alpha).mean()\n","\n","# Create subplots with independent y-axis for reputers (log-transformed) and shared y-axis for inferers and forecasters\n","fig = make_subplots(rows=1, cols=3, \n","                    subplot_titles=(\"Average Reputer Score\", \n","                                    \"Average Inferer Score\", \n","                                    \"Average Forecaster Score\"),\n","                    horizontal_spacing=0.05,  # Reduce horizontal spacing\n","                    shared_yaxes=False)  # Set shared_yaxes=False for separate scales\n","\n","# Plot reputer average with log-transformed data (First subplot)\n","fig.add_trace(go.Scatter(\n","    x=reputer_avg['epoch'], \n","    y=reputer_avg['log_metric_value'],  # Use log-transformed values\n","    mode='lines+markers', \n","    line=dict(color=reputer_color, width=2),  # Increased line width\n","    marker=dict(color=reputer_color),\n","    name='Average of reputer scores (Log)',\n","    hovertemplate='Reputer Avg: %{y:.2f}<extra></extra>'\n","), row=1, col=1)\n","\n","# Add EMA for reputer scores\n","fig.add_trace(go.Scatter(\n","    x=reputer_avg['epoch'],\n","    y=reputer_avg['ema'],\n","    mode='lines',\n","    line=dict(color='red', width=2, dash='solid'),  # Red solid line for EMA\n","    name='EMA (Reputer)',\n","    hovertemplate='EMA: %{y:.2f}<extra></extra>'\n","), row=1, col=1)\n","\n","# Plot inferer average (Second subplot)\n","fig.add_trace(go.Scatter(\n","    x=inferer_avg['epoch'], \n","    y=inferer_avg['metric_value'],\n","    mode='lines+markers', \n","    line=dict(color=inferer_color, width=2),  # Increased line width\n","    marker=dict(color=inferer_color),\n","    name='Average of inferer scores',\n","    hovertemplate='Inferer Avg: %{y:.2f}<extra></extra>'\n","), row=1, col=2)\n","\n","# Add EMA for inferer scores\n","fig.add_trace(go.Scatter(\n","    x=inferer_avg['epoch'],\n","    y=inferer_avg['ema'],\n","    mode='lines',\n","    line=dict(color='red', width=2, dash='solid'),  # Red solid line for EMA\n","    name='EMA (Inferer)',\n","    hovertemplate='EMA: %{y:.2f}<extra></extra>'\n","), row=1, col=2)\n","\n","# Plot forecaster average (Third subplot)\n","fig.add_trace(go.Scatter(\n","    x=forecaster_avg['epoch'], \n","    y=forecaster_avg['metric_value'],\n","    mode='lines+markers', \n","    line=dict(color=forecaster_color, width=2),  # Increased line width\n","    marker=dict(color=forecaster_color),\n","    name='Average of forecaster scores',\n","    hovertemplate='Forecaster Avg: %{y:.2f}<extra></extra>'\n","), row=1, col=3)\n","\n","# Add EMA for forecaster scores\n","fig.add_trace(go.Scatter(\n","    x=forecaster_avg['epoch'],\n","    y=forecaster_avg['ema'],\n","    mode='lines',\n","    line=dict(color='red', width=2, dash='solid'),  # Red solid line for EMA\n","    name='EMA (Forecaster)',\n","    hovertemplate='EMA: %{y:.2f}<extra></extra>'\n","), row=1, col=3)\n","\n","# Update layout to use independent y-axes for reputers and shared for others\n","fig.update_layout(\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    font=dict(size=12),  # Set consistent font size for axis labels and ticks\n","    showlegend=False,  # Turn off the legend\n","    margin=dict(l=70, r=30, t=30, b=30),  # Adjust left margin to allow space for y-axis label\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\"\n","    )\n",")\n","\n","# Update x-axes to ensure consistent ticks\n","fig.update_xaxes(\n","    title_text=\"Epoch\",\n","    title_font=dict(size=12), \n","    tickfont=dict(size=12),\n","    showspikes=True,\n","    spikemode='across',\n","    spikesnap='cursor',\n","    spikethickness=1,\n","    spikedash=\"dot\",\n","    spikecolor=\"grey\",\n","    matches='x'  # Ensure all x-axes have the same ticks\n",")\n","\n","# Y-axis for Reputers (First column, log-transformed data)\n","fig.update_yaxes(\n","    title_text=\"Log(Average Score)\",  # Label only for Reputer column\n","    type=\"linear\",  # Use linear scale since the data is manually log-transformed\n","    title_font=dict(size=12), \n","    tickfont=dict(size=12),\n","    showspikes=True,\n","    spikemode='across',\n","    spikesnap='cursor',\n","    spikethickness=1,\n","    spikedash=\"dot\",\n","    spikecolor=\"grey\",\n","    showticklabels=True,  # Ensure ticks are shown\n","    row=1, col=1\n",")\n","\n","# Y-axis for Inferers (Second column)\n","fig.update_yaxes(\n","    title_text=\"Average Score\",  # Label only for Inferer column\n","    title_font=dict(size=12), \n","    tickfont=dict(size=12),\n","    showspikes=True,\n","    spikemode='across',\n","    spikesnap='cursor',\n","    spikethickness=1,\n","    spikedash=\"dot\",\n","    spikecolor=\"grey\",\n","    showticklabels=True,  # Ensure ticks are shown\n","    row=1, col=2\n",")\n","\n","# Y-axis for Forecasters (Third column)\n","fig.update_yaxes(\n","    title_text=\"Average Score\",  # Label for Forecaster column\n","    showspikes=True,\n","    spikemode='across',\n","    spikesnap='cursor',\n","    spikethickness=1,\n","    spikedash=\"dot\",\n","    spikecolor=\"grey\",\n","    showticklabels=True,  # Ensure ticks are shown\n","    row=1, col=3\n",")\n","\n","# Show the plot\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create new interactive plot\n","fig = go.Figure()\n","\n","# Add emission line\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=new_supply_df['block_emission'],\n","        mode='lines+markers',\n","        name='Recomputed Emission',\n","        line=dict(color='blue', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","\n","# Update layout\n","fig.update_layout(\n","    title='Recomputed Emission per Block Values',\n","    xaxis_title='Block Height',\n","    yaxis_title='Actual Emission',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat='.2e',\n","        showexponent='all',\n","        exponentformat='e',\n","        showgrid=True\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["Here I plot the monthly emission per unit staked. Note that this does consider the actual current staked value, this is the value that was stored in the emissions module and was used when performing the emission update:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create new interactive plot\n","fig = go.Figure()\n","\n","# Add emission line\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=new_supply_df['previous_reward_emission_per_unit_staked_token'],\n","        mode='lines+markers',\n","        name='Monthly Emission',\n","        line=dict(color='orange', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","\n","# Update layout\n","fig.update_layout(\n","    title='Monthly Emission Per unit Staked',\n","    xaxis_title='Block Height',\n","    yaxis_title='Monthly Emission',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat='.2e',\n","        showexponent='all',\n","        exponentformat='e',\n","        showgrid=True\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["Here I plot what the new monthly emission would be if we were to compute it at block $$i$$:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create new interactive plot\n","fig = go.Figure()\n","\n","# Add emission line\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=new_supply_df['block_emission']*864000.0/new_supply_df['network_staked'],\n","        mode='lines+markers',\n","        name='Recomputed Monthly Emission',\n","        line=dict(color='green', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","\n","# Update layout\n","fig.update_layout(\n","    title='Recomputed Monthly emission per unit staked',\n","    xaxis_title='Block Height',\n","    yaxis_title='Monthly Emission',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat='.2e',\n","        showexponent='all',\n","        exponentformat='e',\n","        showgrid=True\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["Here we plot the target emission $$\\hat{e}_i$$ if we were to update the emission at block $$i$$:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create new interactive plot\n","fig = go.Figure()\n","\n","# Add emission line\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=new_supply_df['target_reward_emission_per_unit_staked_token'],\n","        mode='lines+markers',\n","        name='Target Emission',\n","        line=dict(color='purple', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","\n","# Update layout\n","fig.update_layout(\n","    title='Target Emission per unit staked',\n","    xaxis_title='Block Height',\n","    yaxis_title='Monthly Emission',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat='.2e',\n","        showexponent='all',\n","        exponentformat='e',\n","        showgrid=True\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Research Metrics"]},{"cell_type":"markdown","metadata":{},"source":["### Fundmental metric"]},{"cell_type":"markdown","metadata":{},"source":["We implement a calculation to verify the emission process. This fundamental metric checks the correctness of emissions at each epoch.\n","\n","- A value of 1 is healthy and indicates that the emission process is functioning correctly! 😁✅\n","- Any deviation from 1 is unhealthy and suggests potential issues with the emission process! 😢😷"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["alpha = 0.1\n","# Create new interactive plot\n","fig = go.Figure()\n","\n","# Add emission line\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=(alpha*new_supply_df['target_reward_emission_per_unit_staked_token']+(1-alpha)*new_supply_df['previous_reward_emission_per_unit_staked_token'])/(new_supply_df['block_emission']*864000.0/new_supply_df['network_staked']),\n","        mode='lines+markers',\n","        name='Fundamental Metric',\n","        line=dict(color='pink', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    title='Fundamental metric (recomputed EMA vs actual emission)',\n","    xaxis_title='Block Height',\n","    yaxis_title='Fundamental Metric',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat='.2e',\n","        showexponent='all',\n","        exponentformat='e',\n","        showgrid=True,\n","        range=[0.9, 1.1]  # Set y-axis limits\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Shift block_emission forward by 1 to compare with current previous_emission\n","new_supply_df['shifted_block_emission'] = new_supply_df['block_emission'].shift(1)\n","new_supply_df['emission_ratio'] = new_supply_df['shifted_block_emission'] / new_supply_df['previous_emission']\n","\n","# new_supply_df['shifted_block_emission'] = new_supply_df['emission_per_unit_staked_token'].shift(1)\n","# new_supply_df['emission_ratio'] = new_supply_df['shifted_block_emission'] / new_supply_df['previous_reward_emission_per_unit_staked_token']\n","\n","# Rest of plotting code stays the same...\n","# Create new interactive plot\n","fig = go.Figure()\n","\n","# Add ratio line\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=new_supply_df['emission_ratio'],\n","        mode='lines+markers',\n","        name='Ratio to Previous Emission',\n","        line=dict(color='blue', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","# Add reference line at 1 (without annotation)\n","fig.add_hline(\n","    y=1, \n","    line_dash=\"dash\", \n","    line_color=\"red\", \n","    opacity=0.7\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    title='Ratio of Recomputed Block Emission to Previous Block Emission Value',\n","    xaxis_title='Block Height',\n","    yaxis_title='Ratio (Block Emission/Previous)',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat='.2e',\n","        showexponent='all',\n","        exponentformat='e',\n","        showgrid=True\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["Here I compare the change in circulating supply (or inflation) to the total emission. A negative value implies that the circulating supply increased less than we thought it would. These measurements are taken every few blocks so there  some noise."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","# Calculate the ratio and apply log10\n","new_supply_df['total_supply_change'] = new_supply_df['circulating_supply'].diff()\n","new_supply_df['block_diff'] = new_supply_df['block_height'].diff()\n","# new_supply_df['change_per_block'] = (new_supply_df['total_supply_change'] / new_supply_df['block_diff']) / actual_current_block_emission\n","new_supply_df['change_per_block'] = (new_supply_df['total_supply_change'] / new_supply_df['block_diff']) / new_supply_df['previous_emission']\n","\n","new_supply_df['log_ratio'] = np.log10(new_supply_df['change_per_block'])\n","\n","# Create new interactive plot\n","fig = go.Figure()\n","\n","# Add log ratio line\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=new_supply_df['log_ratio'],\n","        mode='lines+markers',\n","        name='Log10 Ratio to Current Emission',\n","        line=dict(color='purple', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","# Add reference line at 0 (log10(1) = 0)\n","fig.add_hline(\n","    y=0, \n","    line_dash=\"dash\", \n","    line_color=\"red\", \n","    opacity=0.7,\n",")\n","\n","# Update layout with scientific notation\n","fig.update_layout(\n","    title='Log10 Ratio of Actual Supply Change to Current Block Emission',\n","    xaxis_title='Block Height',\n","    yaxis_title='Log10(Actual/Current)',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat='.2e',\n","        showexponent='all',\n","        exponentformat='e',\n","        showgrid=True\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["Here I compare the decrease in the remainging ecosystem mint supply to the total emission. A value of $$<1$$ implies that the treasury supply decreased less than we thought it would."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate the change in ecosystem supply per block\n","new_supply_df['ecosystem_change'] = new_supply_df['ecosystem_mint_supply_remaining'].diff()\n","new_supply_df['block_diff'] = new_supply_df['block_height'].diff()\n","new_supply_df['ecosystem_change_per_block'] = -(new_supply_df['ecosystem_change'] / new_supply_df['block_diff']) / new_supply_df['previous_emission']\n","\n","# Create new interactive plot\n","fig = go.Figure()\n","\n","# Add ratio line\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=new_supply_df['ecosystem_change_per_block'],\n","        mode='lines+markers',\n","        name='Ratio to Current Emission',\n","        line=dict(color='green', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","# Add reference line at -1\n","fig.add_hline(\n","    y=1, \n","    line_dash=\"dash\", \n","    line_color=\"red\", \n","    opacity=0.7\n",")\n","\n","# ... rest of the code stays the same until update_layout ...\n","\n","# Update layout with scientific notation\n","fig.update_layout(\n","    title='Ratio of Ecosystem Supply Change per Block to Current Block Emission',\n","    xaxis_title='Block Height',\n","    yaxis_title='Ratio (Ecosystem Change/Current Emission)',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat='.10e',  # Scientific notation with 2 decimal places\n","        showexponent='all',\n","        exponentformat='e',\n","        showgrid=True\n","    )\n",")\n","\n","# ... rest of the code stays the same ...\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["Below are plots to monitor the total tokens staked, tokens circulating, and the remaining ecosystem mint balance:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["alpha = 0.1\n","# Create new interactive plot\n","fig = go.Figure()\n","\n","# Add emission line, converting values to millions\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=new_supply_df['circulating_supply'] / 1_000_000,  # Convert to millions\n","        mode='lines+markers',\n","        name='Circulating Supply',\n","        line=dict(color='red', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    title='Circulating Supply',\n","    xaxis_title='Block Height',\n","    yaxis_title='Circulating Supply (Millions)',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat=',',  # Add thousand separators\n","        dtick=0.01,      # Set tick interval to 0.5 million\n","        showgrid=True,\n","        # Add 1% padding to axis range\n","        # range=[\n","        #     (new_supply_df['circulating_supply'].min() / 1_000_000) * 0.99,\n","        #     (new_supply_df['circulating_supply'].max() / 1_000_000) * 1.01\n","        # ]\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Supply monitor"]},{"cell_type":"markdown","metadata":{},"source":["### Inflation rate and treasury decrease rate"]},{"cell_type":"markdown","metadata":{},"source":["### Normalized Emission per Unit Staked"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create new interactive plot\n","fig = go.Figure()\n","\n","# Add emission line, converting values to millions\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=new_supply_df['network_staked'] / 1_000_000,  # Convert to millions\n","        mode='lines+markers',\n","        name='Network Staked',\n","        line=dict(color='blue', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    title='Network Staked',\n","    xaxis_title='Block Height',\n","    yaxis_title='Staked Tokens (Millions)',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat=',',  # Add thousand separators\n","        dtick=0.1,      # Set tick interval to 0.5 million\n","        showgrid=True,\n","        # Add 1% padding to axis range\n","        # range=[\n","        #     (new_supply_df['network_staked'].min() / 1_000_000) * 0.99,\n","        #     (new_supply_df['network_staked'].max() / 1_000_000) * 1.01\n","        # ]\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create interactive plot using plotly\n","fig = go.Figure()\n","\n","# Add ecosystem balance line\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=new_supply_df['ecosystem_balance'],\n","        mode='lines+markers',\n","        name='Ecosystem Balance',\n","        line=dict(color='purple', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    title='Ecosystem Balance Over Time',\n","    xaxis_title='Block Height',\n","    yaxis_title='Ecosystem Balance',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat='.2e',\n","        showexponent='all',\n","        exponentformat='e'\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create interactive plot\n","fig = go.Figure()\n","\n","# Add each locked token category\n","fig.add_trace(\n","    go.Scatter(\n","        x=locked_df['block_height'],\n","        y=locked_df['investors_seed_locked'],\n","        mode='lines',\n","        name='Investors Seed Locked',\n","        line=dict(color='blue', width=2)\n","    )\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=locked_df['block_height'],\n","        y=locked_df['investors_preseed_locked'],\n","        mode='lines',\n","        name='Investors Preseed Locked',\n","        line=dict(color='green', width=2)\n","    )\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=locked_df['block_height'],\n","        y=locked_df['ecosystem_locked'],\n","        mode='lines',\n","        name='Ecosystem Locked',\n","        line=dict(color='red', width=2)\n","    )\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=locked_df['block_height'],\n","        y=locked_df['total_locked'],\n","        mode='lines',\n","        name='Total Locked',\n","        line=dict(color='purple', width=2)\n","    )\n",")\n","\n","fig.add_trace(\n","    go.Scatter(\n","        x=locked_df['block_height'],\n","        y=locked_df['team_locked'],\n","        mode='lines',\n","        name='Team Locked',\n","        line=dict(color='orange', width=2)\n","    )\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    title='Locked Token Categories Over Time',\n","    xaxis_title='Block Height',\n","    yaxis_title='Amount Locked',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat='.2e',\n","        showexponent='all',\n","        exponentformat='e'\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["alpha = 0.1\n","# Create new interactive plot\n","fig = go.Figure()\n","\n","# Add emission line, converting values to millions\n","fig.add_trace(\n","    go.Scatter(\n","        x=new_supply_df['block_height'],\n","        y=new_supply_df['ecosystem_mint_supply_remaining'] / 1_000_000,  # Convert to millions\n","        mode='lines+markers',\n","        name='Ecosystem Mint Supply Remaining',\n","        line=dict(color='green', width=2),\n","        marker=dict(size=6, opacity=0.7)\n","    )\n",")\n","\n","# Update layout\n","fig.update_layout(\n","    title='Ecosystem Mint Supply Remaining',\n","    xaxis_title='Block Height',\n","    yaxis_title='Supply Remaining (Millions)',\n","    showlegend=True,\n","    hovermode='x unified',\n","    template='plotly_white',\n","    yaxis=dict(\n","        tickformat=',',  # Add thousand separators\n","        dtick=0.01,      # Set tick interval to 0.5 million\n","        showgrid=True,\n","        # Add 1% padding to axis range\n","        # range=[\n","        #     (new_supply_df['ecosystem_mint_supply_remaining'].min() / 1_000_000) * 0.99,\n","        #     (new_supply_df['ecosystem_mint_supply_remaining'].max() / 1_000_000) * 1.01\n","        # ]\n","    )\n",")\n","\n","# Add grid\n","fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n","\n","# Display plot\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["- Let $$P_i$$ be the valdidator reward distribution at epoch $$i$$\n","- First we define the entropy as\n","    - $$E_i = -\\sum_{m=1}^{n_r} P_{im} \\ln\\left( P_{im}\\right) \\left( \\frac{n_{r,eff}}{n_r}\\right)^\\beta$$\n","    - where $$n_{r,eff} =  \\frac{1}{\\sum_{m=1}^{n_r} P_{im}^2},$$ and $$\\beta = 0.25$$\n","- Then, we plot\n","    - $$    H_i = 10^{C_r(E_i / \\ln(n_r) - 1)}$$\n","    - with $$C_r = 1$$\n","- This metric is bounded on the interval $$[0,1]$$\n","- A **large/close to 1** value is **healthy** and corresponds to the valdidators having similar rewards 😁✅\n","- A **small/close to 0** value is **unhealthy** and corresponds to the valdidators having varying rewards 😢😷"]},{"cell_type":"markdown","metadata":{},"source":["## Validator Rewards"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Sort validator_df by block height\n","validator_df = validator_df.sort_values(by='block_height').copy()\n","\n","# Calculate EMA directly on the normalized values with alpha = 0.1\n","alpha = 0.1\n","ema_values = validator_df['normalized_amount'].ewm(alpha=alpha).mean()\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define Viridis color for the line\n","validator_color = '#3b528b'  # Mid blue from Viridis\n","\n","# Add original data points\n","fig.add_trace(go.Scatter(\n","    x=validator_df['block_height'],\n","    y=validator_df['normalized_amount'],\n","    mode='lines+markers',\n","    name='Validator Reward Metric',\n","    line=dict(color=validator_color),\n","    marker=dict(color=validator_color),\n","    hovertemplate='Distribution Metric: %{y:.2f}<extra></extra>'\n","))\n","\n","# Add EMA line (red) on top of the original values\n","fig.add_trace(go.Scatter(\n","    x=validator_df['block_height'],\n","    y=ema_values,\n","    mode='lines',\n","    name='EMA',\n","    line=dict(color='red', dash='solid', width=2),\n","    hovertemplate='EMA: %{y:.2f}<extra></extra>'\n","))\n","\n","# Update the layout\n","fig.update_layout(\n","    title=\"Validator Reward Distribution Metric over Block Heights\",\n","    xaxis_title=\"Block Height\",\n","    yaxis_title=\"Distribution Metric\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    # Add log scale to y-axis\n","    yaxis_type=\"log\",\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import plotly.graph_objects as go\n","\n","# Sort DataFrame by epoch\n","new_ema_score_df = new_ema_scores_df.sort_values(by='epoch')\n","\n","# Calculate EMA with alpha = 0.1\n","alpha = 0.1\n","ema_values = new_ema_score_df['active_participants'].ewm(alpha=alpha).mean()\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define Viridis color for the Active Inferers line\n","active_inferers_color = '#fde725'  # Bright yellow from Viridis\n","\n","# Plot Active Inferers line\n","fig.add_trace(go.Scatter(\n","    x=new_ema_score_df['epoch'],\n","    y=new_ema_score_df['active_participants'],\n","    mode='lines+markers',\n","    name='Active Inferers',\n","    line=dict(color=active_inferers_color),\n","    marker=dict(color=active_inferers_color),\n","    hovertemplate='Active Inferers: %{y}<extra></extra>'\n","))\n","\n","# Add EMA line with red color\n","fig.add_trace(go.Scatter(\n","    x=new_ema_score_df['epoch'],\n","    y=ema_values,\n","    mode='lines',\n","    name='EMA',\n","    line=dict(color='red', dash='solid', width=2),\n","    hovertemplate='EMA: %{y:.2f}<extra></extra>'\n","))\n","\n","# Update the layout with Viridis style settings\n","fig.update_layout(\n","    title=\"Active Inferers Over Time\",\n","    xaxis_title=\"Epoch\",\n","    yaxis_title=\"Number of Active Inferers\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import plotly.graph_objects as go\n","\n","# Sort DataFrame by epoch\n","new_ema_score_df = new_ema_score_df.sort_values(by='epoch')\n","\n","# Calculate EMA with alpha = 0.1\n","alpha = 0.1\n","ema_values = new_ema_score_df['new_addresses'].ewm(alpha=alpha).mean()\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define color for the New Inferers line\n","new_inferers_color = '#21918c'  # Teal from Viridis\n","\n","# Plot New Inferers line\n","fig.add_trace(go.Scatter(\n","    x=new_ema_score_df['epoch'],\n","    y=new_ema_score_df['new_addresses'],\n","    mode='lines+markers',\n","    name='New Inferers',\n","    line=dict(color=new_inferers_color),\n","    marker=dict(color=new_inferers_color),\n","    hovertemplate='New Inferers: %{y}<extra></extra>'\n","))\n","\n","# Add EMA line with red color\n","fig.add_trace(go.Scatter(\n","    x=new_ema_score_df['epoch'],\n","    y=ema_values/2,\n","    mode='lines',\n","    name='EMA',\n","    line=dict(color='red', dash='solid', width=2),\n","    hovertemplate='EMA: %{y:.2f}<extra></extra>'\n","))\n","\n","# Update the layout with Viridis style settings\n","fig.update_layout(\n","    title=\"New Inferers Over Time\",\n","    xaxis_title=\"Epoch\",\n","    yaxis_title=\"Number of New Inferers\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import plotly.graph_objects as go\n","import numpy as np\n","\n","# Sort DataFrame by epoch\n","new_ema_score_df = new_ema_score_df.sort_values(by='epoch')\n","\n","# Calculate the lifetime metric (log10 of the ratio)\n","lifetime_metric = np.log10(new_ema_score_df['active_participants'] / (new_ema_score_df['new_addresses'] + 1e-2))\n","\n","# Calculate EMA with alpha = 0.1\n","alpha = 0.1\n","ema_values = lifetime_metric.ewm(alpha=alpha).mean()\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define color for the Lifetime Metric line\n","metric_color = '#440154'  # Deep purple from Viridis\n","\n","# Plot Lifetime Metric line\n","fig.add_trace(go.Scatter(\n","    x=new_ema_score_df['epoch'],\n","    y=lifetime_metric,\n","    mode='lines+markers',\n","    name='Inferer Lifetime',\n","    line=dict(color=metric_color),\n","    marker=dict(color=metric_color),\n","    hovertemplate='Lifetime Metric: %{y:.2f}<extra></extra>'\n","))\n","\n","# Add EMA line with red color\n","fig.add_trace(go.Scatter(\n","    x=new_ema_score_df['epoch'],\n","    y=ema_values,\n","    mode='lines',\n","    name='EMA',\n","    line=dict(color='red', dash='solid', width=2),\n","    hovertemplate='EMA: %{y:.2f}<extra></extra>'\n","))\n","\n","# Update the layout with Viridis style settings\n","fig.update_layout(\n","    title=\"Inferer Lifetime Metric Over Time\",\n","    xaxis_title=\"Epoch\",\n","    yaxis_title=\"log10(Active / (New + 0.01))\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import plotly.graph_objects as go\n","import numpy as np\n","\n","# Sort DataFrame by epoch\n","new_ema_score_df = new_ema_score_df.sort_values(by='epoch')\n","\n","# Calculate the sortition time metric (log10 of the ratio)\n","sortition_metric = np.log10(new_ema_score_df['total_participants'] / (new_ema_score_df['new_addresses'] + 1e-2))\n","\n","# Calculate EMA with alpha = 0.1\n","alpha = 0.1\n","ema_values = sortition_metric.ewm(alpha=alpha).mean()\n","\n","# Create the plot\n","fig = go.Figure()\n","\n","# Define color for the Sortition Time Metric line\n","metric_color = '#3b528b'  # Blue-purple from Viridis\n","\n","# Plot Sortition Time Metric line\n","fig.add_trace(go.Scatter(\n","    x=new_ema_score_df['epoch'],\n","    y=sortition_metric,\n","    mode='lines+markers',\n","    name='Sortition Time',\n","    line=dict(color=metric_color),\n","    marker=dict(color=metric_color),\n","    hovertemplate='Sortition Time Metric: %{y:.2f}<extra></extra>'\n","))\n","\n","# Add EMA line with red color\n","fig.add_trace(go.Scatter(\n","    x=new_ema_score_df['epoch'],\n","    y=ema_values,\n","    mode='lines',\n","    name='EMA',\n","    line=dict(color='red', dash='solid', width=2),\n","    hovertemplate='EMA: %{y:.2f}<extra></extra>'\n","))\n","\n","# Update the layout with Viridis style settings\n","fig.update_layout(\n","    title=\"Sortition Time Metric Over Time\",\n","    xaxis_title=\"Epoch\",\n","    yaxis_title=\"log10(Total / (New + 0.01))\",\n","    height=500,\n","    width=800,\n","    template=\"plotly_white\",\n","    hovermode=\"x unified\",\n","    spikedistance=-1,\n","    xaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    yaxis=dict(\n","        showspikes=True,\n","        spikemode='across',\n","        spikesnap='cursor',\n","        spikethickness=1,\n","        showline=True,\n","        showgrid=True,\n","        spikedash=\"dot\",\n","        spikecolor=\"grey\"\n","    ),\n","    hoverlabel=dict(\n","        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n","        bordercolor=\"rgba(0, 0, 0, 0)\",\n","        font_size=12,\n","        font_family=\"Arial\",\n","        namelength=-1\n","    )\n",")\n","\n","# Show the plot\n","fig.show()"]}],"metadata":{"hex_info":{"author":null,"exported_date":"Fri Jan 17 2025 17:09:25 GMT+0000 (Coordinated Universal Time)","project_id":"82134b21-962b-4a82-9ff1-028627017c7f","version":"draft"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":4}
